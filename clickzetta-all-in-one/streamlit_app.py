"""
ClickZetta LangChain All-in-One Demo

é›†æˆå±•ç¤ºæ‰€æœ‰ ClickZetta å­˜å‚¨æœåŠ¡å’Œ LangChain åŠŸèƒ½çš„ç»¼åˆæ¼”ç¤ºå¹³å°ã€‚
ä¸€ä¸ªé¡µé¢ä½“éªŒæ‰€æœ‰åŠŸèƒ½ï¼šæ–‡æ¡£æ‘˜è¦ã€æ™ºèƒ½é—®ç­”ã€æ··åˆæœç´¢ã€SQLé—®ç­”ã€ç½‘ç»œçˆ¬è™«ã€‚
"""

import streamlit as st
import os
import hashlib
import time
from datetime import datetime
import re
import json

# è¾…åŠ©å‡½æ•°ï¼šæ¸…ç†æ§åˆ¶å­—ç¬¦
def clean_message_content(content):
    """æ¸…ç†æ¶ˆæ¯å†…å®¹ä¸­çš„JSONæ§åˆ¶å­—ç¬¦"""
    if not content:
        return content

    if isinstance(content, str):
        # ç§»é™¤æˆ–æ›¿æ¢æ§åˆ¶å­—ç¬¦ï¼Œä¿ç•™æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦
        cleaned = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content)
        return cleaned
    return content

def safe_get_chat_history(chat_memory):
    """å®‰å…¨è·å–èŠå¤©å†å²ï¼Œå¤„ç†JSONæ§åˆ¶å­—ç¬¦é”™è¯¯"""
    try:
        return chat_memory.buffer if chat_memory else []
    except Exception as e:
        print(f"Failed to retrieve messages: {e}")  # è¿™æ˜¯æ—¥å¿—ä¸­çœ‹åˆ°çš„é”™è¯¯
        return []  # è¿”å›ç©ºå†å²è€Œä¸æ˜¯å´©æºƒ

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

# é¦–å…ˆå°è¯•åŠ è½½å½“å‰ç›®å½•çš„ .envï¼Œç„¶åå°è¯•çˆ¶ç›®å½•çš„ .env
env_loaded = load_dotenv('.env')
if not env_loaded:
    env_loaded = load_dotenv('../.env')
if not env_loaded:
    st.warning("âš ï¸ æœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ç¯å¢ƒå˜é‡å·²æ­£ç¡®é…ç½®")

try:
    import requests
    from bs4 import BeautifulSoup
    import html2text
    import validators
    import pandas as pd
    import plotly.express as px
    from langchain_core.documents import Document
    from langchain_community.embeddings import DashScopeEmbeddings
    from langchain_clickzetta import (
        ClickZettaEngine,
        ClickZettaStore,
        ClickZettaDocumentStore,
        ClickZettaFileStore,
        ClickZettaVectorStore,
        ClickZettaHybridStore,
        ClickZettaChatMessageHistory
    )
    from langchain.chains import LLMChain
    from langchain.prompts import PromptTemplate
    from langchain_community.llms import Tongyi

    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    DEPENDENCIES_AVAILABLE = False
    st.error(f"ç¼ºå°‘ä¾èµ–: {e}")
    st.stop()

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="ClickZetta LangChain All-in-One Demo",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ·å¼å®šä¹‰
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .feature-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

# ä¸»æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <h1>ğŸš€ ClickZetta LangChain All-in-One Demo</h1>
    <p>ä¸€ç«™å¼ä½“éªŒæ‰€æœ‰ ClickZetta å­˜å‚¨æœåŠ¡ã€æ£€ç´¢æœåŠ¡ä¸ LangChain çš„é›†æˆ</p>
</div>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'engine' not in st.session_state:
    st.session_state.engine = None
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
if 'demo_data' not in st.session_state:
    st.session_state.demo_data = {}

def init_clickzetta_engine():
    """åˆå§‹åŒ– ClickZetta å¼•æ“"""
    try:
        required_env_vars = [
            'CLICKZETTA_SERVICE',
            'CLICKZETTA_INSTANCE',
            'CLICKZETTA_WORKSPACE',
            'CLICKZETTA_SCHEMA',
            'CLICKZETTA_USERNAME',
            'CLICKZETTA_PASSWORD',
            'CLICKZETTA_VCLUSTER'
        ]

        missing_vars = []
        for var in required_env_vars:
            if not os.getenv(var):
                missing_vars.append(var)

        if missing_vars:
            st.error(f"ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
            st.info("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®è¿™äº›å˜é‡")
            return None

        engine = ClickZettaEngine(
            service=os.getenv('CLICKZETTA_SERVICE'),
            instance=os.getenv('CLICKZETTA_INSTANCE'),
            workspace=os.getenv('CLICKZETTA_WORKSPACE'),
            schema=os.getenv('CLICKZETTA_SCHEMA'),
            username=os.getenv('CLICKZETTA_USERNAME'),
            password=os.getenv('CLICKZETTA_PASSWORD'),
            vcluster=os.getenv('CLICKZETTA_VCLUSTER')
        )

        return engine

    except Exception as e:
        st.error(f"ClickZetta å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def init_ai_services():
    """åˆå§‹åŒ– AI æœåŠ¡"""
    try:
        api_key = os.getenv('DASHSCOPE_API_KEY')
        if not api_key:
            st.error("è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
            return None, None

        embeddings = DashScopeEmbeddings(
            model="text-embedding-v2",
            dashscope_api_key=api_key
        )

        llm = Tongyi(
            model_name="qwen-turbo",
            dashscope_api_key=api_key,
            temperature=0.7
        )

        return embeddings, llm

    except Exception as e:
        st.error(f"AI æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return None, None


def chunk_text(text, max_length=2000):
    """å°†é•¿æ–‡æœ¬åˆ†å—ï¼Œç¡®ä¿æ¯å—ä¸è¶…è¿‡æŒ‡å®šé•¿åº¦"""
    if len(text) <= max_length:
        return [text]

    chunks = []
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = text.split('\n\n')
    current_chunk = ""

    for paragraph in paragraphs:
        # å¦‚æœå½“å‰æ®µè½æœ¬èº«å°±è¶…é•¿ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
        if len(paragraph) > max_length:
            # å…ˆå¤„ç†å½“å‰ç§¯ç´¯çš„å†…å®¹
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = ""

            # æŒ‰å¥å­åˆ†å‰²é•¿æ®µè½
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', paragraph)
            for sentence in sentences:
                if not sentence.strip():
                    continue
                sentence = sentence.strip() + 'ã€‚'

                # å¦‚æœå•ä¸ªå¥å­å°±è¶…é•¿ï¼Œéœ€è¦å¼ºåˆ¶åˆ†å‰²
                if len(sentence) > max_length:
                    # å¼ºåˆ¶æŒ‰å­—ç¬¦åˆ†å‰²
                    while len(sentence) > max_length:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                            current_chunk = ""
                        chunks.append(sentence[:max_length])
                        sentence = sentence[max_length:]
                    if sentence:
                        current_chunk = sentence
                elif len(current_chunk + sentence) <= max_length:
                    current_chunk += sentence
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence
        else:
            # æ­£å¸¸æ®µè½å¤„ç†
            if len(paragraph) > max_length:
                # æ®µè½æœ¬èº«è¶…é•¿ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                # æŒ‰å¥å­åˆ†å‰²é•¿æ®µè½
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', paragraph)
                for sentence in sentences:
                    if not sentence.strip():
                        continue
                    sentence = sentence.strip() + 'ã€‚'

                    if len(sentence) > max_length:
                        # å¥å­è¿˜æ˜¯å¤ªé•¿ï¼Œå¼ºåˆ¶åˆ†å‰²
                        while len(sentence) > max_length:
                            if current_chunk:
                                chunks.append(current_chunk.strip())
                                current_chunk = ""
                            chunks.append(sentence[:max_length])
                            sentence = sentence[max_length:]
                        if sentence:
                            current_chunk = sentence
                    elif len(current_chunk + sentence) <= max_length:
                        current_chunk += sentence
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = sentence
            elif len(current_chunk + paragraph + '\n\n') <= max_length:
                current_chunk += paragraph + '\n\n'
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph + '\n\n'

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


def sanitize_content_for_sql(content):
    """
    å¯¹æ–‡æ¡£å†…å®¹è¿›è¡Œæ¸…ç†ï¼Œé¿å… SQL æ³¨å…¥å’Œè§£æé”™è¯¯
    """
    if not content:
        return content

    # ç§»é™¤æˆ–æ›¿æ¢å¯èƒ½å¯¼è‡´SQLè§£æé—®é¢˜çš„å­—ç¬¦
    sanitized = content

    # æ›¿æ¢ç©ºå­—èŠ‚
    sanitized = sanitized.replace('\x00', '')

    # å¤„ç†å¼•å· - è½¬ä¹‰å•å¼•å·å’ŒåŒå¼•å·
    sanitized = sanitized.replace("'", "''")
    sanitized = sanitized.replace('"', '""')

    # å¤„ç†åæ–œæ 
    sanitized = sanitized.replace('\\', '\\\\')

    # å¤„ç†æ§åˆ¶å­—ç¬¦ï¼Œä½†ä¿ç•™å¸¸è§çš„æ¢è¡Œç¬¦
    control_chars = ['\x01', '\x02', '\x03', '\x04', '\x05', '\x06', '\x07', '\x08',
                    '\x0b', '\x0c', '\x0e', '\x0f', '\x10', '\x11', '\x12', '\x13',
                    '\x14', '\x15', '\x16', '\x17', '\x18', '\x19', '\x1a', '\x1b',
                    '\x1c', '\x1d', '\x1e', '\x1f']

    for char in control_chars:
        sanitized = sanitized.replace(char, '')

    # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿çš„æ–‡æœ¬å¯¼è‡´SQLæ€§èƒ½é—®é¢˜
    max_length = 100000  # 100KB æ–‡æœ¬é™åˆ¶
    if len(sanitized) > max_length:
        sanitized = sanitized[:max_length] + "...[å†…å®¹è¢«æˆªæ–­]"

    return sanitized


def process_long_text(text, llm, operation="æ‘˜è¦"):
    """å¤„ç†é•¿æ–‡æœ¬ï¼Œæ”¯æŒåˆ†å—å¤„ç†"""
    chunks = chunk_text(text)

    if len(chunks) == 1:
        # æ–‡æœ¬é•¿åº¦åˆé€‚ï¼Œç›´æ¥å¤„ç†
        st.write("ğŸ“ æ­£åœ¨ç”Ÿæˆæ‘˜è¦...")
        if operation == "æ‘˜è¦":
            prompt = PromptTemplate(
                input_variables=["content"],
                template="""è¯·å¯¹ä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´å‡†ç¡®çš„æ‘˜è¦ï¼Œçªå‡ºå…³é”®ä¿¡æ¯ï¼š

å†…å®¹ï¼š
{content}

æ‘˜è¦ï¼š"""
            )
        else:
            prompt = PromptTemplate(
                input_variables=["content"],
                template="""è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š

å†…å®¹ï¼š
{content}

åˆ†æï¼š"""
            )

        chain = LLMChain(llm=llm, prompt=prompt)
        return chain.run(content=text)

    else:
        # æ–‡æœ¬è¿‡é•¿ï¼Œéœ€è¦åˆ†å—å¤„ç†
        st.write(f"ğŸ“‹ æ–‡æœ¬å·²åˆ†ä¸º {len(chunks)} ä¸ªéƒ¨åˆ†")

        # ä¼˜åŒ–ç­–ç•¥æç¤º
        if len(chunks) > 10:
            st.warning(f"âš ï¸ æ£€æµ‹åˆ°å¤§å‹æ–‡æ¡£ï¼ˆ{len(chunks)}ä¸ªåˆ†å—ï¼‰ã€‚å¤„ç†æ—¶é—´çº¦éœ€ {len(chunks) * 3} ç§’ã€‚")

            # æä¾›å¿«é€Ÿæ‘˜è¦é€‰é¡¹
            if st.checkbox("ğŸš€ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆåˆå¹¶ç›¸ä¼¼æ®µè½ï¼‰", value=True):
                # æ™ºèƒ½åˆå¹¶ç›¸ä¼¼é•¿åº¦çš„åˆ†å—
                optimized_chunks = []
                current_batch = ""

                for chunk in chunks:
                    if len(current_batch + chunk) <= 2000:  # ç¡®ä¿ä¸è¶…è¿‡APIé™åˆ¶
                        current_batch += "\n\n" + chunk if current_batch else chunk
                    else:
                        if current_batch:
                            optimized_chunks.append(current_batch)
                        current_batch = chunk

                if current_batch:
                    optimized_chunks.append(current_batch)

                chunks = optimized_chunks
                st.info(f"ğŸ“Š ä¼˜åŒ–ååˆ†ä¸º {len(chunks)} ä¸ªéƒ¨åˆ†ï¼ˆå‡å°‘ {((len(chunk_text(text)) - len(chunks)) / len(chunk_text(text)) * 100):.0f}% å¤„ç†æ—¶é—´ï¼‰")

        st.write(f"ğŸ”„ å¼€å§‹å¤„ç† {len(chunks)} ä¸ªéƒ¨åˆ†...")
        chunk_results = []

        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        start_time = time.time()

        for i, chunk in enumerate(chunks):
            # æ›´æ–°è¿›åº¦å’Œæ—¶é—´ä¼°ç®—
            progress = (i + 1) / len(chunks)
            progress_bar.progress(progress)

            if i > 0:
                elapsed = time.time() - start_time
                remaining = (elapsed / i) * (len(chunks) - i)
                status_text.write(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(chunks)} éƒ¨åˆ† ({len(chunk)} å­—ç¬¦) - é¢„è®¡å‰©ä½™ {remaining:.0f} ç§’")
            else:
                status_text.write(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(chunks)} éƒ¨åˆ† ({len(chunk)} å­—ç¬¦)...")

            if operation == "æ‘˜è¦":
                prompt = PromptTemplate(
                    input_variables=["content", "part"],
                    template="""è¯·å¯¹ä»¥ä¸‹å†…å®¹çš„ç¬¬{part}éƒ¨åˆ†ç”Ÿæˆç®€æ´æ‘˜è¦ï¼š

å†…å®¹ï¼š
{content}

ç®€æ´æ‘˜è¦ï¼š"""
                )
            else:
                prompt = PromptTemplate(
                    input_variables=["content", "part"],
                    template="""è¯·ç®€è¦åˆ†æä»¥ä¸‹å†…å®¹çš„ç¬¬{part}éƒ¨åˆ†ï¼š

å†…å®¹ï¼š
{content}

ç®€è¦åˆ†æï¼š"""
                )

            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿åˆ†å—ä¸è¶…è¿‡APIé™åˆ¶
            if len(chunk) > 2048:
                st.error(f"âš ï¸ ç¬¬{i+1}éƒ¨åˆ†é•¿åº¦({len(chunk)}å­—ç¬¦)è¶…è¿‡APIé™åˆ¶ï¼Œè·³è¿‡å¤„ç†")
                chunk_results.append(f"[ç¬¬{i+1}éƒ¨åˆ†å†…å®¹è¿‡é•¿ï¼Œå·²è·³è¿‡]")
                continue

            chain = LLMChain(llm=llm, prompt=prompt)
            try:
                result = chain.run(content=chunk, part=f"{i+1}")
                chunk_results.append(result)
            except Exception as e:
                st.error(f"å¤„ç†ç¬¬{i+1}éƒ¨åˆ†æ—¶å‡ºé”™: {e}")
                chunk_results.append(f"[ç¬¬{i+1}éƒ¨åˆ†å¤„ç†å¤±è´¥: {str(e)}]")

        # åˆå¹¶é˜¶æ®µ
        progress_bar.progress(1.0)
        status_text.write("ğŸ”— æ­£åœ¨åˆå¹¶å„éƒ¨åˆ†ç»“æœ...")

        # åˆå¹¶å„éƒ¨åˆ†ç»“æœ
        combined_content = "\n\n".join([f"ç¬¬{i+1}éƒ¨åˆ†{operation}ï¼š{result}" for i, result in enumerate(chunk_results)])

        if operation == "æ‘˜è¦":
            final_prompt = PromptTemplate(
                input_variables=["summaries"],
                template="""è¯·å°†ä»¥ä¸‹å„éƒ¨åˆ†æ‘˜è¦åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„ç»¼åˆæ‘˜è¦ï¼š

{summaries}

ç»¼åˆæ‘˜è¦ï¼š"""
            )
        else:
            final_prompt = PromptTemplate(
                input_variables=["analyses"],
                template="""è¯·å°†ä»¥ä¸‹å„éƒ¨åˆ†åˆ†æåˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„ç»¼åˆåˆ†æï¼š

{analyses}

ç»¼åˆåˆ†æï¼š"""
            )

        final_chain = LLMChain(llm=llm, prompt=final_prompt)
        final_result = final_chain.run(summaries=combined_content) if operation == "æ‘˜è¦" else final_chain.run(analyses=combined_content)

        # æ¸…ç†è¿›åº¦æ˜¾ç¤º
        progress_bar.empty()
        status_text.write("âœ… å¤„ç†å®Œæˆï¼")

        return final_result


class ClickZettaAllInOneDemo:
    """ClickZetta All-in-One æ¼”ç¤ºç±»"""

    def __init__(self):
        self.engine = None
        self.embeddings = None
        self.llm = None
        self.doc_store = None
        self.cache_store = None
        self.file_store = None
        self.vector_store = None
        self.hybrid_store = None
        self.chat_history = None

    def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            # åˆå§‹åŒ–å¼•æ“
            self.engine = init_clickzetta_engine()
            if not self.engine:
                return False

            # åˆå§‹åŒ– AI æœåŠ¡
            self.embeddings, self.llm = init_ai_services()
            if not self.embeddings or not self.llm:
                return False

            # åˆå§‹åŒ–å­˜å‚¨æœåŠ¡
            self.doc_store = ClickZettaDocumentStore(
                engine=self.engine,
                table_name="allinone_documents"
            )

            self.cache_store = ClickZettaStore(
                engine=self.engine,
                table_name="allinone_cache"
            )

            self.file_store = ClickZettaFileStore(
                engine=self.engine,
                volume_type="user",
                subdirectory="allinone_files"
            )

            self.vector_store = ClickZettaVectorStore(
                engine=self.engine,
                embeddings=self.embeddings,
                table_name="allinone_vectors"
            )

            self.hybrid_store = ClickZettaHybridStore(
                engine=self.engine,
                embeddings=self.embeddings,
                table_name="allinone_hybrid"
            )

            self.chat_history = ClickZettaChatMessageHistory(
                engine=self.engine,
                session_id="allinone_session",
                table_name="allinone_chat_history"
            )

            return True

        except Exception as e:
            st.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def get_all_stats(self):
        """è·å–æ‰€æœ‰å­˜å‚¨æœåŠ¡çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}

        try:
            # æ–‡æ¡£ç»Ÿè®¡
            try:
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šå…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                table_check_query = f"SHOW TABLES LIKE '%{self.doc_store.table_name.split('.')[-1]}%'"
                try:
                    table_exists = self.engine.execute_query(table_check_query)
                    stats["documents_debug"] = {
                        "table_name": self.doc_store.table_name,
                        "table_exists": len(table_exists) > 0 if table_exists else False,
                        "table_check_result": table_exists
                    }
                except Exception as te:
                    stats["documents_debug"] = {
                        "table_name": self.doc_store.table_name,
                        "table_check_error": str(te)
                    }

                doc_result = self.engine.execute_query(f"""
                    SELECT
                        COUNT(*) as doc_count,
                        AVG(LENGTH(doc_content)) as avg_length
                    FROM {self.doc_store.table_name}
                """)
                if doc_result and len(doc_result) > 0:
                    row = doc_result[0]
                    if isinstance(row, dict):
                        stats["documents"] = row
                        stats["documents_debug"]["query_result"] = row
                    else:
                        # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œå¯èƒ½æ˜¯åˆ—è¡¨æˆ–å…ƒç»„
                        result_dict = {"doc_count": row[0] if len(row) > 0 else 0, "avg_length": row[1] if len(row) > 1 else 0}
                        stats["documents"] = result_dict
                        stats["documents_debug"]["query_result"] = result_dict
                else:
                    stats["documents"] = {"doc_count": 0, "avg_length": 0}
                    stats["documents_debug"]["query_result"] = "No results returned"
            except Exception as e:
                stats["documents"] = {"doc_count": 0, "avg_length": 0}
                stats["documents_debug"]["error"] = str(e)

            # ç¼“å­˜ç»Ÿè®¡
            try:
                cache_result = self.engine.execute_query(f"""
                    SELECT COUNT(*) as cache_count
                    FROM {self.cache_store.table_name}
                """)
                if cache_result and len(cache_result) > 0:
                    row = cache_result[0]
                    if isinstance(row, dict):
                        stats["cache"] = row
                    else:
                        stats["cache"] = {"cache_count": row[0] if len(row) > 0 else 0}
                else:
                    stats["cache"] = {"cache_count": 0}
            except Exception as e:
                stats["cache"] = {"cache_count": 0}

            # æ–‡ä»¶ç»Ÿè®¡
            try:
                files = self.file_store.list_files()
                total_size = sum(file_info[1] for file_info in files if len(file_info) >= 2)
                stats["files"] = {"file_count": len(files), "total_size": total_size}
            except:
                stats["files"] = {"file_count": 0, "total_size": 0}

            # å‘é‡ç»Ÿè®¡
            try:
                vector_result = self.engine.execute_query(f"""
                    SELECT COUNT(*) as vector_count
                    FROM {self.vector_store.table_name}
                """)
                if vector_result and len(vector_result) > 0:
                    row = vector_result[0]
                    if isinstance(row, dict):
                        stats["vectors"] = row
                    else:
                        stats["vectors"] = {"vector_count": row[0] if len(row) > 0 else 0}
                else:
                    stats["vectors"] = {"vector_count": 0}
            except Exception as e:
                stats["vectors"] = {"vector_count": 0}

            # æ··åˆå­˜å‚¨ç»Ÿè®¡
            try:
                hybrid_result = self.engine.execute_query(f"""
                    SELECT COUNT(*) as hybrid_count
                    FROM {self.hybrid_store.table_name}
                """)
                if hybrid_result and len(hybrid_result) > 0:
                    row = hybrid_result[0]
                    if isinstance(row, dict):
                        stats["hybrid"] = row
                    else:
                        stats["hybrid"] = {"hybrid_count": row[0] if len(row) > 0 else 0}
                else:
                    stats["hybrid"] = {"hybrid_count": 0}
            except Exception as e:
                stats["hybrid"] = {"hybrid_count": 0}

            # èŠå¤©å†å²ç»Ÿè®¡
            try:
                chat_result = self.engine.execute_query(f"""
                    SELECT COUNT(*) as message_count
                    FROM {self.chat_history.table_name}
                """)
                if chat_result and len(chat_result) > 0:
                    row = chat_result[0]
                    if isinstance(row, dict):
                        stats["chat"] = row
                    else:
                        stats["chat"] = {"message_count": row[0] if len(row) > 0 else 0}
                else:
                    stats["chat"] = {"message_count": 0}
            except Exception as e:
                stats["chat"] = {"message_count": 0}

        except Exception as e:
            st.warning(f"ç»Ÿè®¡ä¿¡æ¯è·å–å¤±è´¥: {e}")
            stats = {
                "documents": {"doc_count": 0, "avg_length": 0},
                "cache": {"cache_count": 0},
                "files": {"file_count": 0, "total_size": 0},
                "vectors": {"vector_count": 0},
                "hybrid": {"hybrid_count": 0},
                "chat": {"message_count": 0}
            }

        return stats

def safe_get_metric_value(stats_dict, category, key, default=0):
    """å®‰å…¨åœ°ä»ç»Ÿè®¡å­—å…¸ä¸­æå–æŒ‡æ ‡å€¼ï¼Œå¤„ç†åµŒå¥—ç»“æ„"""
    try:
        category_data = stats_dict.get(category, {})
        if isinstance(category_data, dict):
            value = category_data.get(key, default)

            # å¤„ç†åµŒå¥—ç»“æ„çš„æƒ…å†µï¼Œå¦‚ {"doc_count": {"doc_count": 6, "avg_length": 123}}
            if isinstance(value, dict) and key in value:
                # å¦‚æœvalueæ˜¯å­—å…¸ä¸”åŒ…å«åŒåkeyï¼Œåˆ™æå–å†…éƒ¨å€¼
                nested_value = value.get(key, default)
                if isinstance(nested_value, (int, float)):
                    return nested_value
                elif isinstance(nested_value, str):
                    try:
                        return float(nested_value)
                    except ValueError:
                        return nested_value
                else:
                    return default

            # ç¡®ä¿è¿”å›å€¼æ˜¯ st.metric æ¥å—çš„ç±»å‹
            if value is None:
                return default
            # ç¡®ä¿æ•°å€¼ç±»å‹
            if isinstance(value, (int, float)):
                return value
            elif isinstance(value, str):
                try:
                    return float(value)
                except ValueError:
                    return value
            else:
                return default
        else:
            return default
    except Exception as e:
        # åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºé”™è¯¯
        return default

def show_overview():
    """æ˜¾ç¤ºç³»ç»Ÿæ¦‚è§ˆ"""
    st.header("ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo
    try:
        stats = demo.get_all_stats()

        # ç¡®ä¿ stats æ˜¯å­—å…¸ç±»å‹
        if not isinstance(stats, dict):
            st.error("ç»Ÿè®¡æ•°æ®æ ¼å¼å¼‚å¸¸")
            return

        # åˆ›å»ºæŒ‡æ ‡å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "ğŸ“„ æ–‡æ¡£æ€»æ•°",
                safe_get_metric_value(stats, "documents", "doc_count", 0),
                help="å­˜å‚¨åœ¨ DocumentStore ä¸­çš„æ–‡æ¡£æ•°é‡"
            )

        with col2:
            st.metric(
                "ğŸ’¾ ç¼“å­˜æ¡ç›®",
                safe_get_metric_value(stats, "cache", "cache_count", 0),
                help="é”®å€¼å­˜å‚¨ä¸­çš„ç¼“å­˜æ¡ç›®æ•°"
            )

        with col3:
            file_count = safe_get_metric_value(stats, "files", "file_count", 0)
            st.metric(
                "ğŸ“ æ–‡ä»¶æ•°é‡",
                file_count,
                help="Volume å­˜å‚¨ä¸­çš„æ–‡ä»¶æ•°é‡"
            )

        with col4:
            st.metric(
                "ğŸ” å‘é‡è®°å½•",
                safe_get_metric_value(stats, "vectors", "vector_count", 0),
                help="å‘é‡å­˜å‚¨ä¸­çš„è®°å½•æ•°"
            )
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return

    # å­˜å‚¨ç±»å‹åˆ†å¸ƒå›¾è¡¨
    if any(stats.values()):
        st.subheader("å­˜å‚¨ç±»å‹åˆ†å¸ƒ")

        storage_data = {
            "æ–‡æ¡£å­˜å‚¨": safe_get_metric_value(stats, "documents", "doc_count", 0),
            "é”®å€¼å­˜å‚¨": safe_get_metric_value(stats, "cache", "cache_count", 0),
            "æ–‡ä»¶å­˜å‚¨": safe_get_metric_value(stats, "files", "file_count", 0),
            "å‘é‡å­˜å‚¨": safe_get_metric_value(stats, "vectors", "vector_count", 0),
            "æ··åˆå­˜å‚¨": safe_get_metric_value(stats, "hybrid", "hybrid_count", 0),
            "èŠå¤©å†å²": safe_get_metric_value(stats, "chat", "message_count", 0)
        }

        # ç¡®ä¿æ‰€æœ‰æ•°å€¼éƒ½æ˜¯æœ‰æ•ˆçš„
        clean_storage_data = {}
        for key, value in storage_data.items():
            if isinstance(value, (int, float)) and value > 0:
                clean_storage_data[key] = value
            elif isinstance(value, str) and value.isdigit() and int(value) > 0:
                clean_storage_data[key] = int(value)

        if clean_storage_data:
            df = pd.DataFrame(list(clean_storage_data.items()), columns=["å­˜å‚¨ç±»å‹", "æ•°é‡"])
        else:
            df = pd.DataFrame()  # ç©ºçš„ DataFrame

        if not df.empty:
            col1, col2 = st.columns(2)

            with col1:
                fig_pie = px.pie(df, values="æ•°é‡", names="å­˜å‚¨ç±»å‹", title="å­˜å‚¨ç±»å‹åˆ†å¸ƒ")
                st.plotly_chart(fig_pie, use_container_width=True)

            with col2:
                fig_bar = px.bar(df, x="å­˜å‚¨ç±»å‹", y="æ•°é‡", title="å„å­˜å‚¨ç±»å‹æ•°æ®é‡")
                st.plotly_chart(fig_bar, use_container_width=True)

def show_document_storage():
    """æ–‡æ¡£å­˜å‚¨åŠŸèƒ½"""
    st.header("ğŸ“ æ–‡æ¡£å­˜å‚¨ç®¡ç†")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¡ åŠŸèƒ½è¯´æ˜</h4>
        <p><strong>ğŸ“ æ–‡æ¡£å­˜å‚¨</strong> - å°†æ–‡æ¡£å†…å®¹åŒæ—¶å­˜å‚¨åˆ°ä¸‰ä¸ªClickZettaå­˜å‚¨ç»„ä»¶ï¼š</p>
        <p>â€¢ <strong>ğŸ“„ DocumentStore</strong> (<code>allinone_documents</code>è¡¨) - å­˜å‚¨ç»“æ„åŒ–æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®</p>
        <p>â€¢ <strong>ğŸ” VectorStore</strong> (<code>allinone_vectors</code>è¡¨) - è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£å‘é‡ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢</p>
        <p>â€¢ <strong>âš¡ HybridStore</strong> (<code>allinone_hybrid</code>è¡¨) - æ”¯æŒæ··åˆæœç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰</p>
        <p><strong>ğŸ¯ ç”¨é€”ï¼š</strong>ä¼ä¸šçŸ¥è¯†åº“æ„å»ºï¼Œä¸ºåç»­æ™ºèƒ½é—®ç­”å’Œæœç´¢æä¾›æ•°æ®åŸºç¡€</p>
    </div>
    """, unsafe_allow_html=True)

    # è¾“å…¥æ–¹å¼é€‰æ‹©
    input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼:", ["æ–‡æœ¬è¾“å…¥", "æ–‡ä»¶ä¸Šä¼ "], horizontal=True, key="doc_storage_input_method")

    content = ""
    if input_method == "æ–‡æœ¬è¾“å…¥":
        content = st.text_area(
            "è¾“å…¥æ–‡æ¡£å†…å®¹:",
            height=300,
            placeholder="è¯·è¾“å…¥è¦å­˜å‚¨çš„æ–‡æ¡£å†…å®¹...",
            key="doc_storage_text_input"
        )
    else:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶:",
            type=['txt', 'md'],
            help="æ”¯æŒ .txt å’Œ .md æ–‡ä»¶"
        )
        if uploaded_file:
            content = str(uploaded_file.read(), "utf-8")
            st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆ:", content, height=150, disabled=True, key="doc_storage_file_preview")

    # æ–‡æ¡£æ ‡é¢˜è¾“å…¥
    doc_title = st.text_input("æ–‡æ¡£æ ‡é¢˜ (å¯é€‰):", placeholder="è¾“å…¥æ–‡æ¡£æ ‡é¢˜")

    if st.button("ğŸ’¾ å­˜å‚¨æ–‡æ¡£", type="primary") and content.strip():
        with st.spinner("æ­£åœ¨å­˜å‚¨æ–‡æ¡£..."):
            try:
                st.info(f"ğŸ“Š æ–‡æ¡£é•¿åº¦: {len(content)} å­—ç¬¦")

                doc_id = hashlib.md5(content.encode()).hexdigest()
                metadata = {
                    "type": "document",
                    "title": doc_title or "æœªå‘½åæ–‡æ¡£",
                    "created_at": datetime.now().isoformat(),
                    "word_count": len(content.split()),
                    "char_count": len(content)
                }

                # æ­¥éª¤1ï¼šå­˜å‚¨åˆ° DocumentStore
                with st.expander("ğŸ’¾ å­˜å‚¨è¿›åº¦", expanded=True):
                    st.write("ğŸ—„ï¸ æ­£åœ¨å­˜å‚¨åˆ° DocumentStore...")
                    # å¯¹å†…å®¹è¿›è¡Œæ¸…ç†ä»¥é¿å…SQLè§£æé”™è¯¯
                    sanitized_content = sanitize_content_for_sql(content)
                    demo.doc_store.store_document(
                        doc_id=doc_id,
                        content=sanitized_content,
                        metadata=metadata
                    )
                    st.write("âœ… DocumentStore å­˜å‚¨å®Œæˆ")

                    # å­˜å‚¨åˆ° VectorStore ä»¥æ”¯æŒæœç´¢å’Œé—®ç­”
                    st.write("ğŸ” æ­£åœ¨å­˜å‚¨åˆ° VectorStore...")

                    # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œè¿›è¡Œåˆ†å—å­˜å‚¨
                    if len(content) > 2000:
                        st.write("ğŸ“ å†…å®¹è¾ƒé•¿ï¼Œè¿›è¡Œåˆ†å—å­˜å‚¨...")
                        chunks = chunk_text(content)
                        documents = []
                        for i, chunk in enumerate(chunks):
                            chunk_metadata = {**metadata, "chunk_id": i, "total_chunks": len(chunks)}
                            doc = Document(page_content=chunk, metadata=chunk_metadata)
                            documents.append(doc)
                        demo.vector_store.add_documents(documents)
                        st.write(f"âœ… VectorStore å­˜å‚¨å®Œæˆ ({len(chunks)} ä¸ªåˆ†å—)")
                    else:
                        doc = Document(page_content=content, metadata=metadata)
                        demo.vector_store.add_documents([doc])
                        st.write("âœ… VectorStore å­˜å‚¨å®Œæˆ")

                    # å¦‚æœæœ‰ HybridStoreï¼Œä¹Ÿå­˜å‚¨åˆ°æ··åˆå­˜å‚¨
                    if demo.hybrid_store:
                        st.write("ğŸ”— æ­£åœ¨å­˜å‚¨åˆ° HybridStore...")
                        if len(content) > 2000:
                            demo.hybrid_store.add_documents(documents)
                        else:
                            demo.hybrid_store.add_documents([doc])
                        st.write("âœ… HybridStore å­˜å‚¨å®Œæˆ")

                    st.write("ğŸ‰ æ–‡æ¡£å­˜å‚¨å®Œæˆï¼")

                # æ˜¾ç¤ºç»“æœ
                st.success("âœ… æ–‡æ¡£å·²æˆåŠŸå­˜å‚¨åˆ°æ‰€æœ‰å­˜å‚¨æœåŠ¡ä¸­ï¼")

                with st.expander("ğŸ“‹ å­˜å‚¨è¯¦æƒ…"):
                    st.json({
                        "æ–‡æ¡£ID": doc_id,
                        "æ ‡é¢˜": metadata["title"],
                        "å­—ç¬¦æ•°": metadata["char_count"],
                        "è¯æ•°": metadata["word_count"],
                        "å­˜å‚¨æ—¶é—´": metadata["created_at"],
                        "åˆ†å—æ•°": len(chunks) if len(content) > 2000 else 1
                    })

                # åˆ·æ–°ç»Ÿè®¡æ•°æ®
                if 'stats_refresh_counter' not in st.session_state:
                    st.session_state.stats_refresh_counter = 0
                st.session_state.stats_refresh_counter += 1
                st.rerun()

            except Exception as e:
                st.error(f"å­˜å‚¨å¤±è´¥: {e}")


def show_intelligent_summary():
    """æ™ºèƒ½æ‘˜è¦åŠŸèƒ½"""
    st.header("ğŸ“„ æ™ºèƒ½æ–‡æ¡£æ‘˜è¦")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¡ åŠŸèƒ½è¯´æ˜</h4>
        <p><strong>ğŸ“„ æ™ºèƒ½æ‘˜è¦</strong> - ç»“åˆAIèƒ½åŠ›çš„æ–‡æ¡£å¤„ç†å’Œå­˜å‚¨ï¼š</p>
        <p>â€¢ <strong>ğŸ¤– é€šä¹‰åƒé—® AI</strong> - è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£æ‘˜è¦ï¼ˆæ™ºèƒ½å†…å®¹æå–ï¼‰</p>
        <p>â€¢ <strong>ğŸ“„ DocumentStore</strong> (<code>allinone_documents</code>è¡¨) - åŒæ—¶å­˜å‚¨åŸæ–‡å’ŒAIæ‘˜è¦</p>
        <p>â€¢ <strong>ğŸ” VectorStore</strong> (<code>allinone_vectors</code>è¡¨) - ä¸ºæ‘˜è¦ç”Ÿæˆå‘é‡è¡¨ç¤º</p>
        <p>â€¢ <strong>âš¡ HybridStore</strong> (<code>allinone_hybrid</code>è¡¨) - æ”¯æŒæ‘˜è¦çš„æ··åˆæœç´¢</p>
        <p><strong>ğŸ¯ ç”¨é€”ï¼š</strong>æ™ºèƒ½å†…å®¹ç®¡ç†ï¼Œé•¿æ–‡æ¡£è‡ªåŠ¨æ‘˜è¦ï¼Œæå‡ä¿¡æ¯è·å–æ•ˆç‡</p>
    </div>
    """, unsafe_allow_html=True)

    # è¾“å…¥æ–¹å¼é€‰æ‹©
    input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼:", ["æ–‡æœ¬è¾“å…¥", "æ–‡ä»¶ä¸Šä¼ "], horizontal=True, key="summary_input_method")

    content = ""
    if input_method == "æ–‡æœ¬è¾“å…¥":
        content = st.text_area(
            "è¯·è¾“å…¥æ–‡æ¡£å†…å®¹:",
            height=200,
            placeholder="åœ¨æ­¤å¤„ç²˜è´´æ‚¨è¦æ‘˜è¦çš„æ–‡æ¡£å†…å®¹...",
            key="summary_text_input"
        )
    else:
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£æ–‡ä»¶:",
            type=['txt', 'md'],
            help="æ”¯æŒ .txt å’Œ .md æ–‡ä»¶"
        )
        if uploaded_file:
            content = str(uploaded_file.read(), "utf-8")
            st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆ:", content, height=150, disabled=True, key="summary_file_preview")

    if st.button("ğŸ¯ å¤„ç†æ–‡æ¡£", type="primary") and content.strip():
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
            try:
                # ç”Ÿæˆæ‘˜è¦ï¼Œæ”¯æŒé•¿æ–‡æœ¬å¤„ç†
                st.info(f"ğŸ“Š æ–‡æœ¬é•¿åº¦: {len(content)} å­—ç¬¦")
                if len(content) > 2000:
                    st.info("ğŸ“ æ£€æµ‹åˆ°é•¿æ–‡æœ¬ï¼Œå°†é‡‡ç”¨åˆ†å—å¤„ç†...")

                # æ­¥éª¤1ï¼šç”Ÿæˆæ‘˜è¦
                with st.expander("ğŸ” æ‘˜è¦ç”Ÿæˆè¿›åº¦", expanded=True):
                    summary = process_long_text(content, demo.llm, operation="æ‘˜è¦")

                # æ­¥éª¤2ï¼šå­˜å‚¨åˆ°å¤šä¸ªå­˜å‚¨æœåŠ¡
                with st.expander("ğŸ’¾ å­˜å‚¨è¿›åº¦", expanded=True):
                    doc_id = hashlib.md5(content.encode()).hexdigest()
                    metadata = {
                        "type": "document_summary",
                        "summary": summary,
                        "created_at": datetime.now().isoformat(),
                        "word_count": len(content.split())
                    }

                    # å­˜å‚¨åˆ° DocumentStore
                    st.write("ğŸ—„ï¸ æ­£åœ¨å­˜å‚¨åˆ° DocumentStore...")
                    # å¯¹å†…å®¹è¿›è¡Œæ¸…ç†ä»¥é¿å…SQLè§£æé”™è¯¯
                    sanitized_content = sanitize_content_for_sql(content)
                    demo.doc_store.store_document(
                        doc_id=doc_id,
                        content=sanitized_content,
                        metadata=metadata
                    )
                    st.write("âœ… DocumentStore å­˜å‚¨å®Œæˆ")

                    # åŒæ—¶å­˜å‚¨åˆ° VectorStore ä»¥æ”¯æŒæœç´¢å’Œé—®ç­”
                    st.write("ğŸ” æ­£åœ¨å­˜å‚¨åˆ° VectorStore...")

                    # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œå­˜å‚¨æ‘˜è¦è€Œä¸æ˜¯åŸæ–‡
                    if len(content) > 2000:
                        vector_content = summary[:2000]  # ä½¿ç”¨æ‘˜è¦ä½œä¸ºå‘é‡å†…å®¹
                        st.write("ğŸ“ å†…å®¹è¿‡é•¿ï¼Œä½¿ç”¨æ‘˜è¦è¿›è¡Œå‘é‡åŒ–...")
                    else:
                        vector_content = content

                    doc = Document(
                        page_content=vector_content,
                        metadata={**metadata, "original_length": len(content)}
                    )
                    demo.vector_store.add_documents([doc])
                    st.write("âœ… VectorStore å­˜å‚¨å®Œæˆ")

                    # å¦‚æœæœ‰ HybridStoreï¼Œä¹Ÿå­˜å‚¨åˆ°æ··åˆå­˜å‚¨
                    if demo.hybrid_store:
                        st.write("ğŸ”— æ­£åœ¨å­˜å‚¨åˆ° HybridStore...")
                        demo.hybrid_store.add_documents([doc])
                        st.write("âœ… HybridStore å­˜å‚¨å®Œæˆ")

                    st.write("ğŸ‰ æ‰€æœ‰å­˜å‚¨æœåŠ¡åŒæ­¥å®Œæˆï¼")

                # æ˜¾ç¤ºç»“æœ
                st.success("âœ… æ‘˜è¦ç”Ÿæˆå¹¶å­˜å‚¨æˆåŠŸï¼")

                st.subheader("ğŸ“ ç”Ÿæˆçš„æ‘˜è¦")
                st.write(summary)

                st.subheader("ğŸ“Š æ–‡æ¡£ä¿¡æ¯")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ–‡æ¡£ID", doc_id[:8] + "...")
                with col2:
                    st.metric("å­—æ•°", len(content.split()))
                with col3:
                    st.metric("å­˜å‚¨æ—¶é—´", datetime.now().strftime("%H:%M:%S"))

                # åˆ·æ–°ç»Ÿè®¡æ•°æ®
                if 'stats_refresh_counter' not in st.session_state:
                    st.session_state.stats_refresh_counter = 0
                st.session_state.stats_refresh_counter += 1
                st.rerun()

            except Exception as e:
                st.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")


def show_qa_system():
    """æ™ºèƒ½é—®ç­”ç³»ç»Ÿ"""
    st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¡ åŠŸèƒ½è¯´æ˜</h4>
        <p><strong>ğŸ’¬ æ™ºèƒ½é—®ç­”</strong> - åŸºäºRAG(æ£€ç´¢å¢å¼ºç”Ÿæˆ)çš„å¯¹è¯ç³»ç»Ÿï¼š</p>
        <p>â€¢ <strong>ğŸ” VectorStore</strong> (<code>allinone_vectors</code>è¡¨) - è¯­ä¹‰æ£€ç´¢ç›¸å…³æ–‡æ¡£</p>
        <p>â€¢ <strong>ğŸ¤– é€šä¹‰åƒé—® AI</strong> - åŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆå›ç­”</p>
        <p>â€¢ <strong>ğŸ’¬ ChatMessageHistory</strong> (<code>allinone_chat_history</code>è¡¨) - ä¿å­˜å¯¹è¯å†å²</p>
        <p><strong>ğŸ¯ ç”¨é€”ï¼š</strong>æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œä¼ä¸šçŸ¥è¯†é—®ç­”ï¼ŒAIåŠ©æ‰‹åº”ç”¨</p>
    </div>
    """, unsafe_allow_html=True)

    # æ˜¾ç¤ºèŠå¤©å†å² - æ·»åŠ é”™è¯¯å¤„ç†
    try:
        if hasattr(demo.chat_history, 'messages') and demo.chat_history.messages:
            st.subheader("ğŸ’­ èŠå¤©å†å²")
            for message in demo.chat_history.messages[-5:]:  # æ˜¾ç¤ºæœ€è¿‘5æ¡
                if message.type == "human":
                    st.chat_message("user").write(message.content)
                else:
                    st.chat_message("assistant").write(message.content)
    except Exception as e:
        # é™é»˜å¤„ç†èŠå¤©å†å²é”™è¯¯ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
        if st.session_state.get('debug_mode', False):
            st.warning(f"èŠå¤©å†å²åŠ è½½å¤±è´¥: {e}")
        pass

    # é—®ç­”è¾“å…¥
    question = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:", placeholder="ä¾‹å¦‚ï¼šè¯·æ€»ç»“ä¸€ä¸‹åˆšæ‰æ‘˜è¦çš„æ–‡æ¡£å†…å®¹")

    if st.button("ğŸ¤” è·å–ç­”æ¡ˆ", type="primary") and question.strip():
        with st.spinner("æ­£åœ¨æ€è€ƒç­”æ¡ˆ..."):
            try:
                # æ£€ç´¢ç›¸å…³æ–‡æ¡£
                docs = demo.vector_store.similarity_search(question, k=3)

                if docs:
                    context = "\n".join([doc.page_content for doc in docs])

                    prompt = PromptTemplate(
                        input_variables=["context", "question"],
                        template="""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š"""
                    )

                    chain = LLMChain(llm=demo.llm, prompt=prompt)
                    answer = chain.run(context=context, question=question)
                else:
                    answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨å·²å­˜å‚¨çš„æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"

                # ä¿å­˜åˆ°èŠå¤©å†å²
                demo.chat_history.add_user_message(question)
                demo.chat_history.add_ai_message(answer)

                # æ˜¾ç¤ºç­”æ¡ˆ
                st.chat_message("user").write(question)
                st.chat_message("assistant").write(answer)

                if docs:
                    with st.expander("ğŸ“š å‚è€ƒæ–‡æ¡£"):
                        for i, doc in enumerate(docs, 1):
                            st.write(f"**æ–‡æ¡£ {i}:**")
                            st.write(doc.page_content[:200] + "...")

            except Exception as e:
                st.error(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")

def show_search_system():
    """æœç´¢ç³»ç»Ÿ"""
    st.header("ğŸ” æ··åˆæœç´¢ç³»ç»Ÿ")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¡ åŠŸèƒ½è¯´æ˜</h4>
        <p><strong>ğŸ” æ··åˆæœç´¢</strong> - æœ€å¼ºå¤§çš„æœç´¢ä½“éªŒï¼š</p>
        <p>â€¢ <strong>âš¡ HybridStore</strong> (<code>allinone_hybrid</code>è¡¨) - æ ¸å¿ƒæ··åˆæœç´¢å¼•æ“</p>
        <p>â€¢ <strong>ğŸ§  è¯­ä¹‰æœç´¢</strong> - ç†è§£æŸ¥è¯¢æ„å›¾ï¼Œæ‰¾åˆ°ç›¸å…³æ¦‚å¿µ</p>
        <p>â€¢ <strong>ğŸ”¤ å…³é”®è¯æœç´¢</strong> - ç²¾ç¡®åŒ¹é…ç‰¹å®šè¯æ±‡</p>
        <p>â€¢ <strong>âš–ï¸ æ™ºèƒ½èåˆ</strong> - å¯è°ƒæƒé‡ï¼Œå¹³è¡¡ä¸¤ç§æœç´¢ç»“æœ</p>
        <p><strong>ğŸ¯ ç”¨é€”ï¼š</strong>ä¼ä¸šå†…éƒ¨æœç´¢ï¼Œç”µå•†å•†å“æœç´¢ï¼Œæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns([3, 1])
    with col1:
        search_query = st.text_input("æœç´¢å…³é”®è¯:", placeholder="è¾“å…¥æ‚¨è¦æœç´¢çš„å†…å®¹...")
    with col2:
        search_type = st.selectbox("æœç´¢ç±»å‹:", ["æ··åˆæœç´¢", "è¯­ä¹‰æœç´¢", "å…³é”®è¯æœç´¢"])

    if st.button("ğŸ” å¼€å§‹æœç´¢", type="primary") and search_query.strip():
        with st.spinner("æœç´¢ä¸­..."):
            try:
                if search_type == "è¯­ä¹‰æœç´¢":
                    results = demo.vector_store.similarity_search(search_query, k=5)
                elif search_type == "å…³é”®è¯æœç´¢":
                    # ç®€å•çš„å…³é”®è¯æœç´¢ï¼ˆå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨å…¨æ–‡æœç´¢ï¼‰
                    docs = demo.vector_store.similarity_search(search_query, k=10)
                    results = [doc for doc in docs if search_query.lower() in doc.page_content.lower()]
                else:  # æ··åˆæœç´¢
                    results = demo.hybrid_store.similarity_search(search_query, k=5)

                if results:
                    st.success(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ")

                    for i, result in enumerate(results, 1):
                        with st.expander(f"ç»“æœ {i}: {result.metadata.get('type', 'æ–‡æ¡£')}"):
                            st.write("**å†…å®¹:**")
                            st.write(result.page_content[:300] + ("..." if len(result.page_content) > 300 else ""))

                            if result.metadata:
                                st.write("**å…ƒæ•°æ®:**")
                                for key, value in result.metadata.items():
                                    st.write(f"- {key}: {value}")
                else:
                    st.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")

            except Exception as e:
                st.error(f"æœç´¢å¤±è´¥: {e}")

def show_web_crawler():
    """ç½‘ç»œçˆ¬è™«åŠŸèƒ½"""
    st.header("ğŸ•·ï¸ ç½‘ç»œçˆ¬è™«æ¼”ç¤º")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¡ åŠŸèƒ½è¯´æ˜</h4>
        <p><strong>ğŸ•·ï¸ ç½‘ç»œçˆ¬è™«</strong> - å¤šå­˜å‚¨ååŒçš„æ•°æ®é‡‡é›†ï¼š</p>
        <p>â€¢ <strong>ğŸ“„ DocumentStore</strong> (<code>allinone_documents</code>è¡¨) - å­˜å‚¨æå–çš„æ–‡æœ¬å†…å®¹</p>
        <p>â€¢ <strong>ğŸ“ FileStore</strong> (<code>allinone_files</code> Volume) - å­˜å‚¨åŸå§‹HTMLæ–‡ä»¶</p>
        <p>â€¢ <strong>ğŸ” VectorStore</strong> (<code>allinone_vectors</code>è¡¨) - ç”Ÿæˆå†…å®¹å‘é‡</p>
        <p>â€¢ <strong>ğŸ”‘ Store</strong> (<code>allinone_cache</code>è¡¨) - ç¼“å­˜çˆ¬å–çŠ¶æ€</p>
        <p><strong>ğŸ¯ ç”¨é€”ï¼š</strong>ç½‘é¡µæ•°æ®é‡‡é›†ï¼Œå†…å®¹èšåˆå¹³å°ï¼Œç«å“ä¿¡æ¯ç›‘æ§</p>
    </div>
    """, unsafe_allow_html=True)

    url = st.text_input(
        "ç½‘é¡µURL:",
        value="https://www.yunqi.tech",
        placeholder="è¾“å…¥è¦çˆ¬å–çš„ç½‘é¡µURL..."
    )

    if st.button("ğŸš€ å¼€å§‹çˆ¬å–", type="primary") and url.strip():
        if not validators.url(url):
            st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„URL")
            return

        with st.spinner("æ­£åœ¨çˆ¬å–ç½‘é¡µ..."):
            try:
                # çˆ¬å–ç½‘é¡µ
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()

                # è§£æå†…å®¹
                soup = BeautifulSoup(response.content, 'html.parser')
                title = soup.find('title').get_text() if soup.find('title') else "æ— æ ‡é¢˜"

                # æå–æ–‡æœ¬å†…å®¹
                h = html2text.HTML2Text()
                h.ignore_links = True
                h.ignore_images = True
                text_content = h.handle(response.text)

                # ç”ŸæˆID
                url_hash = hashlib.md5(url.encode()).hexdigest()

                # å­˜å‚¨åˆ° DocumentStore
                # å¯¹ç½‘é¡µå†…å®¹è¿›è¡Œæ¸…ç†ä»¥é¿å…SQLè§£æé”™è¯¯
                sanitized_text_content = sanitize_content_for_sql(text_content)
                demo.doc_store.store_document(
                    doc_id=url_hash,
                    content=sanitized_text_content,
                    metadata={
                        "url": url,
                        "title": title,
                        "crawled_at": datetime.now().isoformat(),
                        "type": "web_page",
                        "word_count": len(text_content.split())
                    }
                )

                # å­˜å‚¨åˆ° FileStore (åŸå§‹HTML)
                demo.file_store.store_file(
                    file_path=f"{url_hash}.html",
                    content=response.content,
                    mime_type="text/html"
                )

                # å­˜å‚¨åˆ° VectorStore
                doc = Document(
                    page_content=text_content,
                    metadata={
                        "url": url,
                        "title": title,
                        "type": "web_page"
                    }
                )
                demo.vector_store.add_documents([doc])

                # ç¼“å­˜çˆ¬å–çŠ¶æ€
                demo.cache_store.mset([(f"crawl_status:{url_hash}", b"completed")])

                # æ˜¾ç¤ºç»“æœ
                st.markdown("""
                <div class="success-box">
                    <h4>âœ… ç½‘é¡µçˆ¬å–æˆåŠŸï¼</h4>
                    <p>å†…å®¹å·²å­˜å‚¨åˆ°å¤šä¸ª ClickZetta å­˜å‚¨æœåŠ¡</p>
                </div>
                """, unsafe_allow_html=True)

                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ğŸ“Š çˆ¬å–ä¿¡æ¯")
                    st.metric("ç½‘é¡µæ ‡é¢˜", title)
                    st.metric("å†…å®¹é•¿åº¦", f"{len(text_content)} å­—ç¬¦")
                    st.metric("å­—æ•°ç»Ÿè®¡", f"{len(text_content.split())} è¯")

                with col2:
                    st.subheader("ğŸ—‚ï¸ å­˜å‚¨åˆ†å¸ƒ")
                    st.write("âœ… DocumentStore - æ–‡æœ¬å†…å®¹")
                    st.write("âœ… FileStore - åŸå§‹HTML")
                    st.write("âœ… VectorStore - å‘é‡ç´¢å¼•")
                    st.write("âœ… Cache - çˆ¬å–çŠ¶æ€")

                # å†…å®¹é¢„è§ˆ
                with st.expander("ğŸ“„ å†…å®¹é¢„è§ˆ"):
                    st.write(text_content[:500] + ("..." if len(text_content) > 500 else ""))

                # åˆ·æ–°ç»Ÿè®¡æ•°æ®
                if 'stats_refresh_counter' not in st.session_state:
                    st.session_state.stats_refresh_counter = 0
                st.session_state.stats_refresh_counter += 1
                st.rerun()

            except Exception as e:
                st.error(f"çˆ¬å–å¤±è´¥: {e}")

def show_sql_chat():
    """SQL èŠå¤©åŠŸèƒ½"""
    st.header("ğŸ’¾ SQL æ™ºèƒ½é—®ç­”")

    if not st.session_state.get('initialized', False):
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸­åˆå§‹åŒ–ç³»ç»Ÿ")
        return

    demo = st.session_state.demo

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¡ åŠŸèƒ½è¯´æ˜</h4>
        <p><strong>ğŸ’¾ SQLæ™ºèƒ½é—®ç­”</strong> - ç›´æ¥è®¿é—®åº•å±‚æ•°æ®çš„ä¸¤ç§æ–¹å¼ï¼š</p>
        <p>â€¢ <strong>ğŸ¤– è‡ªç„¶è¯­è¨€è½¬SQL</strong> - AIå°†é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢</p>
        <p>â€¢ <strong>ğŸ“ ç›´æ¥SQLæ‰§è¡Œ</strong> - æ‰‹å†™SQLç›´æ¥æŸ¥è¯¢æ•°æ®åº“</p>
        <p>â€¢ <strong>ğŸ”§ ClickZetta Engine</strong> - ç›´æ¥æ‰§è¡ŒSQLï¼Œè®¿é—®æ‰€æœ‰è¡¨</p>
        <p>â€¢ <strong>ğŸ“Š ç»“æœå¯è§†åŒ–</strong> - è¡¨æ ¼å½¢å¼å±•ç¤ºæŸ¥è¯¢ç»“æœ</p>
        <p><strong>ğŸ¯ ç”¨é€”ï¼š</strong>æ•°æ®åˆ†æï¼Œç³»ç»Ÿè°ƒè¯•ï¼Œè¡¨ç»“æ„æŸ¥çœ‹ï¼Œç»Ÿè®¡æŠ¥è¡¨</p>
    </div>
    """, unsafe_allow_html=True)

    # æ˜¾ç¤ºå¯ç”¨çš„è¡¨
    st.subheader("ğŸ“‹ å¯ç”¨æ•°æ®è¡¨")
    tables = [
        f"{demo.doc_store.table_name} - æ–‡æ¡£å­˜å‚¨è¡¨",
        f"{demo.cache_store.table_name} - é”®å€¼ç¼“å­˜è¡¨",
        f"{demo.vector_store.table_name} - å‘é‡å­˜å‚¨è¡¨",
        f"{demo.chat_history.table_name} - èŠå¤©å†å²è¡¨"
    ]

    for table in tables:
        st.write(f"â€¢ {table}")

    # SQL æŸ¥è¯¢è¾“å…¥
    query_type = st.radio("æŸ¥è¯¢æ–¹å¼:", ["è‡ªç„¶è¯­è¨€", "ç›´æ¥SQL"], horizontal=True)

    if query_type == "è‡ªç„¶è¯­è¨€":
        nl_query = st.text_input(
            "è‡ªç„¶è¯­è¨€æŸ¥è¯¢:",
            placeholder="ä¾‹å¦‚ï¼šæ˜¾ç¤ºæ‰€æœ‰æ–‡æ¡£çš„æ•°é‡å’Œæ ‡é¢˜"
        )

        if st.button("ğŸ” æ‰§è¡ŒæŸ¥è¯¢", type="primary") and nl_query.strip():
            with st.spinner("æ­£åœ¨ç”ŸæˆSQL..."):
                try:
                    # ç”Ÿæˆ SQL
                    prompt = PromptTemplate(
                        input_variables=["query", "tables"],
                        template="""æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œç”Ÿæˆå¯¹åº”çš„SQLè¯­å¥ã€‚è¯·åªè¿”å›çº¯SQLè¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡æœ¬ã€‚

å¯ç”¨è¡¨ï¼š
{tables}

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¯·ç”Ÿæˆæ ‡å‡†çš„SQLæŸ¥è¯¢è¯­å¥ï¼š"""
                    )

                    chain = LLMChain(llm=demo.llm, prompt=prompt)
                    # ç¡®ä¿æŸ¥è¯¢æ–‡æœ¬ç¼–ç æ­£ç¡®
                    clean_query = nl_query.encode('utf-8', errors='ignore').decode('utf-8')
                    sql_query = chain.run(
                        query=clean_query,
                        tables="\n".join(tables)
                    )

                    # æ¸…ç†ç”Ÿæˆçš„SQLä¸­çš„æ— æ•ˆå­—ç¬¦å’Œæ ¼å¼é—®é¢˜
                    sql_query = sql_query.strip().encode('utf-8', errors='ignore').decode('utf-8')

                    # ç§»é™¤å¸¸è§çš„æ ¼å¼é—®é¢˜
                    if sql_query.startswith('```sql'):
                        sql_query = sql_query[6:]
                    if sql_query.endswith('```'):
                        sql_query = sql_query[:-3]

                    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
                    sql_query = '\n'.join(line.strip() for line in sql_query.split('\n') if line.strip())

                    # ç¡®ä¿ä»¥åˆ†å·ç»“å°¾ï¼ˆå¦‚æœä¸æ˜¯ä»¥åˆ†å·ç»“å°¾ï¼‰
                    if not sql_query.endswith(';'):
                        sql_query += ';'

                    st.code(sql_query, language="sql")

                    # æ‰§è¡Œ SQLï¼ˆè¿™é‡Œéœ€è¦å®‰å…¨æ£€æŸ¥ï¼‰
                    if st.button("â–¶ï¸ æ‰§è¡Œç”Ÿæˆçš„SQL"):
                        try:
                            # ç¡®ä¿SQLè¯­å¥ç¼–ç æ­£ç¡®
                            clean_sql_exec = sql_query.strip().encode('utf-8', errors='ignore').decode('utf-8')
                            result = demo.engine.execute_query(clean_sql_exec)
                            if result:
                                df = pd.DataFrame(result)
                                st.dataframe(df)
                            else:
                                st.info("æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›æ•°æ®")
                        except Exception as e:
                            st.error(f"SQLæ‰§è¡Œå¤±è´¥: {e}")

                except Exception as e:
                    st.error(f"SQLç”Ÿæˆå¤±è´¥: {e}")
    else:
        sql_query = st.text_area(
            "SQLæŸ¥è¯¢:",
            height=100,
            placeholder="SELECT * FROM table_name LIMIT 10",
            key="sql_query_input"
        )

        if st.button("â–¶ï¸ æ‰§è¡ŒSQL", type="primary") and sql_query.strip():
            try:
                # æ¸…ç†SQLæŸ¥è¯¢ä¸­çš„æ— æ•ˆå­—ç¬¦
                clean_sql = sql_query.strip().encode('utf-8', errors='ignore').decode('utf-8')
                result = demo.engine.execute_query(clean_sql)
                if result:
                    df = pd.DataFrame(result)
                    st.dataframe(df)

                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.write(f"è¿”å› {len(result)} è¡Œæ•°æ®")
                else:
                    st.info("æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›æ•°æ®")
            except Exception as e:
                st.error(f"SQLæ‰§è¡Œå¤±è´¥: {e}")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    # è°ƒè¯•æ¨¡å¼å¼€å…³
    debug_mode = st.checkbox("ğŸ› è°ƒè¯•æ¨¡å¼", value=st.session_state.get('debug_mode', False))
    st.session_state.debug_mode = debug_mode

    if not st.session_state.get('initialized', False):
        if st.button("ğŸš€ åˆå§‹åŒ–ç³»ç»Ÿ", type="primary"):
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–..."):
                demo = ClickZettaAllInOneDemo()
                if demo.initialize():
                    st.session_state.demo = demo
                    st.session_state.initialized = True
                    st.success("ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.error("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
    else:
        st.success("âœ… ç³»ç»Ÿå·²å°±ç»ª")

        if st.button("ğŸ”„ é‡æ–°åˆå§‹åŒ–"):
            st.session_state.initialized = False
            st.rerun()

    st.divider()

    # ç¯å¢ƒé…ç½®ä¿¡æ¯
    st.header("ğŸŒ ç¯å¢ƒä¿¡æ¯")

    # æ˜¾ç¤ºç¯å¢ƒé…ç½®çŠ¶æ€
    def show_env_config():
        """æ˜¾ç¤ºç¯å¢ƒé…ç½®çŠ¶æ€"""
        # ClickZetta é…ç½®
        clickzetta_configs = [
            ("CLICKZETTA_SERVICE", "æœåŠ¡åœ°å€"),
            ("CLICKZETTA_INSTANCE", "å®ä¾‹åç§°"),
            ("CLICKZETTA_WORKSPACE", "å·¥ä½œç©ºé—´"),
            ("CLICKZETTA_SCHEMA", "æ¨¡å¼åç§°"),
            ("CLICKZETTA_USERNAME", "ç”¨æˆ·å"),
            ("CLICKZETTA_VCLUSTER", "è™šæ‹Ÿé›†ç¾¤")
        ]

        # DashScope é…ç½®
        dashscope_api_key = os.getenv("DASHSCOPE_API_KEY", "")

        # ClickZetta é…ç½®çŠ¶æ€
        with st.expander("ğŸ“Š ClickZetta é…ç½®", expanded=False):
            for env_var, display_name in clickzetta_configs:
                value = os.getenv(env_var, "")
                if value:
                    # å¯¹äºæ•æ„Ÿä¿¡æ¯ï¼Œåªæ˜¾ç¤ºå‰å‡ ä½å’Œåå‡ ä½
                    if env_var in ["CLICKZETTA_USERNAME"]:
                        masked_value = f"{value[:3]}{'*' * (len(value) - 6)}{value[-3:]}" if len(value) > 6 else "*" * len(value)
                        st.write(f"âœ… **{display_name}**: `{masked_value}`")
                    else:
                        st.write(f"âœ… **{display_name}**: `{value}`")
                else:
                    st.write(f"âŒ **{display_name}**: æœªé…ç½®")

        # DashScope é…ç½®çŠ¶æ€
        with st.expander("ğŸ¤– DashScope AI é…ç½®", expanded=False):
            if dashscope_api_key:
                # éšè—API Keyçš„å¤§éƒ¨åˆ†å†…å®¹
                masked_key = f"{dashscope_api_key[:8]}{'*' * (len(dashscope_api_key) - 16)}{dashscope_api_key[-8:]}" if len(dashscope_api_key) > 16 else "*" * len(dashscope_api_key)
                st.write(f"âœ… **API Key**: `{masked_key}`")
                st.write("âœ… **çŠ¶æ€**: å·²é…ç½®ï¼Œæ”¯æŒAIåŠŸèƒ½")
            else:
                st.write("âŒ **API Key**: æœªé…ç½®")
                st.write("âš ï¸ **çŠ¶æ€**: AIåŠŸèƒ½ä¸å¯ç”¨ï¼ˆæ‘˜è¦ã€é—®ç­”ã€å‘é‡æœç´¢ï¼‰")

        # ç³»ç»ŸçŠ¶æ€æ€»è§ˆ
        clickzetta_configured = all(os.getenv(env_var) for env_var, _ in clickzetta_configs)
        dashscope_configured = bool(dashscope_api_key)

        st.markdown("**ğŸ“‹ é…ç½®çŠ¶æ€æ€»è§ˆ:**")
        if clickzetta_configured:
            st.success("âœ… ClickZetta: å®Œå…¨é…ç½®")
        else:
            st.error("âŒ ClickZetta: é…ç½®ä¸å®Œæ•´")

        if dashscope_configured:
            st.success("âœ… DashScope: å·²é…ç½®")
        else:
            st.warning("âš ï¸ DashScope: æœªé…ç½®")

    show_env_config()

    st.divider()

    st.header("ğŸ“ˆ å¿«é€Ÿç»Ÿè®¡")
    if st.session_state.get('initialized', False):
        demo = st.session_state.demo

        # æ·»åŠ åˆ·æ–°æŒ‰é’®
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°", key="refresh_stats"):
                st.rerun()

        try:
            stats = demo.get_all_stats()
            # ç¡®ä¿ stats æ˜¯å­—å…¸ç±»å‹
            if isinstance(stats, dict):
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                if st.session_state.get('debug_mode', False):
                    st.json(stats)

                # å¤„ç†å¯èƒ½çš„åµŒå¥—ç»“æ„ï¼Œä»è°ƒè¯•ä¿¡æ¯æ¥çœ‹éœ€è¦ç‰¹åˆ«å¤„ç†
                doc_count = safe_get_metric_value(stats, "documents", "doc_count", 0)
                cache_count = safe_get_metric_value(stats, "cache", "cache_count", 0)
                file_count = safe_get_metric_value(stats, "files", "file_count", 0)
                vector_count = safe_get_metric_value(stats, "vectors", "vector_count", 0)

                st.metric("ğŸ“„ æ–‡æ¡£", doc_count)
                st.metric("ğŸ’¾ ç¼“å­˜", cache_count)
                st.metric("ğŸ“ æ–‡ä»¶", file_count)
                st.metric("ğŸ” å‘é‡", vector_count)
            else:
                st.warning("ç»Ÿè®¡æ•°æ®æ ¼å¼å¼‚å¸¸")
                if st.session_state.get('debug_mode', False):
                    st.write("Stats type:", type(stats))
                    st.write("Stats content:", stats)
        except Exception as e:
            st.error(f"è·å–ç»Ÿè®¡å¤±è´¥: {e}")
            if st.session_state.get('debug_mode', False):
                import traceback
                st.text(traceback.format_exc())


def show_help_documentation():
    """æ˜¾ç¤ºè¯¦ç»†çš„å¸®åŠ©æ–‡æ¡£å’Œæ•™è‚²å†…å®¹"""
    st.header("ğŸ’¡ ClickZetta LangChain å­¦ä¹ æŒ‡å—")

    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ¯ å­¦ä¹ ç›®æ ‡</h4>
        <p>é€šè¿‡è¿™ä¸ªç»¼åˆæ¼”ç¤ºï¼Œæ‚¨å°†æ·±å…¥äº†è§£ ClickZetta LangChain çš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œ
        åŒ…æ‹¬å­˜å‚¨æœåŠ¡çš„å…·ä½“å®ç°ã€è¡¨ç»“æ„è®¾è®¡ã€æœ€ä½³å®è·µç­‰ã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    # åˆ›å»ºå¸®åŠ©æ–‡æ¡£çš„å­æ ‡ç­¾é¡µ
    help_tab1, help_tab2, help_tab3, help_tab4 = st.tabs([
        "ğŸ—ï¸ æ¶æ„åŸç†", "ğŸ—„ï¸ å­˜å‚¨æœåŠ¡è¯¦è§£", "ğŸ“ ä»£ç ç¤ºä¾‹", "ğŸš€ æœ€ä½³å®è·µ"
    ])

    with help_tab1:
        show_architecture_guide()

    with help_tab2:
        show_storage_services_guide()

    with help_tab3:
        show_code_examples()

    with help_tab4:
        show_best_practices()


def show_architecture_guide():
    """æ˜¾ç¤ºæ¶æ„åŸç†æŒ‡å—"""
    st.subheader("ğŸ—ï¸ ClickZetta LangChain æ¶æ„åŸç†")

    # æ•´ä½“æ¶æ„å›¾
    st.markdown("""
    ### ğŸŒŸ æ•´ä½“æ¶æ„

    ClickZetta LangChain æä¾›äº†å®Œæ•´çš„ä¼ä¸šçº§ AI åº”ç”¨å¼€å‘æ ˆï¼š

    ```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  åº”ç”¨å±‚ (Application Layer)           â”‚
    â”‚  â€¢ Streamlit UI  â€¢ FastAPI  â€¢ Jupyter Notebook     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              LangChain é›†æˆå±‚ (Integration Layer)     â”‚
    â”‚  â€¢ Document Processing  â€¢ Chain Management         â”‚
    â”‚  â€¢ Memory Management   â€¢ Agent Framework           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            ClickZetta å­˜å‚¨æœåŠ¡å±‚ (Storage Layer)      â”‚
    â”‚  â€¢ DocumentStore  â€¢ VectorStore  â€¢ HybridStore     â”‚
    â”‚  â€¢ FileStore      â€¢ Store        â€¢ ChatHistory     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              ClickZetta Lakehouse å¼•æ“              â”‚
    â”‚  â€¢ SQL Engine  â€¢ Vector Engine  â€¢ Storage Engine   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```
    """)

    # æ•°æ®æµè½¬ç¤ºä¾‹
    st.markdown("### ğŸ”„ æ•°æ®æµè½¬ç¤ºä¾‹")

    data_flows = {
        "æ–‡æ¡£å¤„ç†æµç¨‹": [
            "ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ â†’ è§£ææå–æ–‡æœ¬",
            "æ–‡æœ¬æ¸…æ´— â†’ å…ƒæ•°æ®æå–",
            "å­˜å‚¨åˆ° DocumentStore â†’ ç”Ÿæˆå‘é‡è¡¨ç¤º",
            "å­˜å‚¨åˆ° VectorStore â†’ å»ºç«‹ç´¢å¼•",
            "åŒæ­¥åˆ° HybridStore â†’ å¯ç”¨æœç´¢"
        ],
        "æ™ºèƒ½é—®ç­”æµç¨‹": [
            "ç”¨æˆ·æé—® â†’ é—®é¢˜å‘é‡åŒ–",
            "VectorStore æ£€ç´¢ â†’ æ‰¾åˆ°ç›¸å…³æ–‡æ¡£",
            "ä¸Šä¸‹æ–‡æ„å»º â†’ LLM ç”Ÿæˆç­”æ¡ˆ",
            "å­˜å‚¨åˆ° ChatHistory â†’ æ›´æ–°å¯¹è¯çŠ¶æ€"
        ],
        "æ··åˆæœç´¢æµç¨‹": [
            "æœç´¢æŸ¥è¯¢ â†’ å…³é”®è¯æå–",
            "å¹¶è¡Œæ‰§è¡Œ â†’ å‘é‡æœç´¢ + å…³é”®è¯æœç´¢",
            "ç»“æœèåˆ â†’ ç›¸å…³æ€§æ’åº",
            "è¿”å›æœ€ç»ˆç»“æœ â†’ ç”¨æˆ·å±•ç¤º"
        ]
    }

    for flow_name, steps in data_flows.items():
        with st.expander(f"ğŸ”„ {flow_name}", expanded=False):
            for i, step in enumerate(steps, 1):
                st.markdown(f"{i}. {step}")


def show_storage_services_guide():
    """æ˜¾ç¤ºå­˜å‚¨æœåŠ¡è¯¦è§£"""
    st.subheader("ğŸ—„ï¸ ClickZetta å­˜å‚¨æœåŠ¡è¯¦è§£")

    # æ˜¾ç¤ºå½“å‰ç³»ç»Ÿçš„å…·ä½“é…ç½®
    if st.session_state.get('initialized', False) and hasattr(st.session_state, 'engine_manager'):
        manager = st.session_state.engine_manager

        st.markdown("### ğŸ“‹ å½“å‰ç³»ç»Ÿé…ç½®")

        # å¼•æ“é…ç½®ä¿¡æ¯
        with st.expander("ğŸ”§ å¼•æ“é…ç½®ä¿¡æ¯", expanded=True):
            engine_info = {
                "ClickZetta Service": os.getenv("CLICKZETTA_SERVICE", "æœªé…ç½®"),
                "Instance": os.getenv("CLICKZETTA_INSTANCE", "æœªé…ç½®"),
                "Workspace": os.getenv("CLICKZETTA_WORKSPACE", "æœªé…ç½®"),
                "Schema": os.getenv("CLICKZETTA_SCHEMA", "æœªé…ç½®"),
                "VCluster": os.getenv("CLICKZETTA_VCLUSTER", "æœªé…ç½®")
            }

            for key, value in engine_info.items():
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.markdown(f"**{key}:**")
                with col2:
                    st.code(value)

        # å­˜å‚¨æœåŠ¡è¯¦æƒ…
        storage_services = [
            {
                "name": "DocumentStore",
                "emoji": "ğŸ“„",
                "description": "ç»“æ„åŒ–æ–‡æ¡£å­˜å‚¨",
                "table_name": "allinone_documents",
                "store_obj": manager.document_store,
                "key_features": [
                    "è‡ªåŠ¨æ–‡æ¡£è§£æå’Œå…ƒæ•°æ®æå–",
                    "æ”¯æŒå…¨æ–‡æœç´¢å’Œæ¡ä»¶æŸ¥è¯¢",
                    "ç‰ˆæœ¬ç®¡ç†å’Œæ–‡æ¡£å†å²",
                    "æ‰¹é‡å¯¼å…¥å’Œå¯¼å‡ºåŠŸèƒ½"
                ]
            },
            {
                "name": "VectorStore",
                "emoji": "ğŸ”",
                "description": "å‘é‡åŒ–å­˜å‚¨å’Œè¯­ä¹‰æœç´¢",
                "table_name": "allinone_vectors",
                "store_obj": manager.vector_store,
                "key_features": [
                    "è‡ªåŠ¨å‘é‡åŒ–å¤„ç†",
                    "é«˜æ€§èƒ½ç›¸ä¼¼åº¦æœç´¢",
                    "æ”¯æŒå¤šç§åµŒå…¥æ¨¡å‹",
                    "å®æ—¶ç´¢å¼•æ›´æ–°"
                ]
            },
            {
                "name": "HybridStore",
                "emoji": "âš¡",
                "description": "æ··åˆæœç´¢å¼•æ“",
                "table_name": "allinone_hybrid",
                "store_obj": manager.hybrid_store,
                "key_features": [
                    "ç»“åˆå‘é‡å’Œå…³é”®è¯æœç´¢",
                    "æ™ºèƒ½ç»“æœèåˆç®—æ³•",
                    "çµæ´»çš„æƒé‡è°ƒæ•´",
                    "å¤šæ¨¡æ€æœç´¢æ”¯æŒ"
                ]
            },
            {
                "name": "FileStore (Volume)",
                "emoji": "ğŸ“",
                "description": "æ–‡ä»¶å­˜å‚¨å’Œç®¡ç†",
                "table_name": "allinone_files (Volume)",
                "store_obj": manager.file_store,
                "key_features": [
                    "å¤§æ–‡ä»¶å­˜å‚¨ä¼˜åŒ–",
                    "æ–‡ä»¶ç‰ˆæœ¬æ§åˆ¶",
                    "è®¿é—®æƒé™ç®¡ç†",
                    "è‡ªåŠ¨å¤‡ä»½å’Œæ¢å¤"
                ]
            },
            {
                "name": "Store (Cache)",
                "emoji": "ğŸ”‘",
                "description": "é”®å€¼å­˜å‚¨å’Œç¼“å­˜",
                "table_name": "allinone_cache",
                "store_obj": manager.cache_store,
                "key_features": [
                    "é«˜æ€§èƒ½é”®å€¼æ“ä½œ",
                    "TTL è¿‡æœŸç®¡ç†",
                    "åˆ†å¸ƒå¼ç¼“å­˜",
                    "åŸå­æ“ä½œæ”¯æŒ"
                ]
            },
            {
                "name": "ChatMessageHistory",
                "emoji": "ğŸ’¬",
                "description": "å¯¹è¯å†å²ç®¡ç†",
                "table_name": "allinone_chat_history",
                "store_obj": manager.chat_memory,
                "key_features": [
                    "ç»“æ„åŒ–æ¶ˆæ¯å­˜å‚¨",
                    "å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†",
                    "å¤šè½®å¯¹è¯æ”¯æŒ",
                    "ç”¨æˆ·ä¼šè¯éš”ç¦»"
                ]
            }
        ]

        for service in storage_services:
            with st.expander(f"{service['emoji']} {service['name']} - {service['description']}", expanded=False):
                col1, col2 = st.columns([1, 1])

                with col1:
                    st.markdown("**ğŸ“Š æœåŠ¡ä¿¡æ¯:**")
                    st.markdown(f"â€¢ **è¡¨å/Volume:** `{service['table_name']}`")

                    # è·å–ç»Ÿè®¡ä¿¡æ¯
                    try:
                        if hasattr(service['store_obj'], 'get_stats'):
                            stats = service['store_obj'].get_stats()
                            if stats:
                                if isinstance(stats, dict):
                                    for key, value in stats.items():
                                        if isinstance(value, (int, float)):
                                            st.markdown(f"â€¢ **{key}:** {value}")
                                        elif isinstance(value, dict) and len(value) == 1:
                                            # å¤„ç†åµŒå¥—ç»“æ„
                                            nested_key = list(value.keys())[0]
                                            nested_value = value[nested_key]
                                            if isinstance(nested_value, (int, float)):
                                                st.markdown(f"â€¢ **{key}:** {nested_value}")
                                else:
                                    st.markdown(f"â€¢ **è®°å½•æ•°:** {stats}")
                            else:
                                st.markdown("â€¢ **çŠ¶æ€:** æš‚æ— æ•°æ®")
                    except Exception as e:
                        st.markdown(f"â€¢ **çŠ¶æ€:** è·å–ç»Ÿè®¡å¤±è´¥ ({str(e)[:50]}...)")

                with col2:
                    st.markdown("**ğŸ¯ æ ¸å¿ƒç‰¹æ€§:**")
                    for feature in service['key_features']:
                        st.markdown(f"â€¢ {feature}")

                # è¡¨ç»“æ„æŸ¥çœ‹åŠŸèƒ½
                if st.button(f"ğŸ” æŸ¥çœ‹ {service['name']} è¡¨ç»“æ„", key=f"schema_{service['name']}"):
                    try:
                        if service['table_name'].endswith('(Volume)'):
                            st.info(f"ğŸ“ {service['name']} ä½¿ç”¨ ClickZetta Volume å­˜å‚¨ï¼Œä¸ºäºŒè¿›åˆ¶æ–‡ä»¶å­˜å‚¨ï¼Œæ— å›ºå®šè¡¨ç»“æ„")
                        else:
                            # å°è¯•è·å–è¡¨ç»“æ„
                            with st.spinner(f"æ­£åœ¨è·å– {service['table_name']} è¡¨ç»“æ„..."):
                                try:
                                    schema_sql = f"DESCRIBE {service['table_name']}"
                                    result = manager.engine.execute_sql(schema_sql)

                                    if result:
                                        st.success(f"âœ… {service['table_name']} è¡¨ç»“æ„:")
                                        if isinstance(result, list) and len(result) > 0:
                                            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºç»“æ„
                                            if isinstance(result[0], dict):
                                                schema_df = pd.DataFrame(result)
                                                st.dataframe(schema_df, use_container_width=True)
                                            else:
                                                for row in result:
                                                    st.write(row)

                                        # æ˜¾ç¤ºç¤ºä¾‹æŸ¥è¯¢
                                        st.markdown("**ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢:**")
                                        sample_queries = {
                                            "allinone_documents": [
                                                f"SELECT COUNT(*) FROM {service['table_name']};",
                                                f"SELECT title, created_at FROM {service['table_name']} LIMIT 5;",
                                                f"SELECT title, LENGTH(content) as content_length FROM {service['table_name']} ORDER BY created_at DESC LIMIT 3;"
                                            ],
                                            "allinone_vectors": [
                                                f"SELECT COUNT(*) FROM {service['table_name']};",
                                                f"SELECT id, document_id FROM {service['table_name']} LIMIT 5;"
                                            ],
                                            "allinone_cache": [
                                                f"SELECT COUNT(*) FROM {service['table_name']};",
                                                f"SELECT key, created_at FROM {service['table_name']} LIMIT 5;"
                                            ]
                                        }

                                        if service['table_name'] in sample_queries:
                                            for query in sample_queries[service['table_name']]:
                                                st.code(query, language="sql")
                                    else:
                                        st.warning(f"âš ï¸ è¡¨ {service['table_name']} å¯èƒ½å°šæœªåˆ›å»ºæˆ–æ— æ•°æ®")

                                except Exception as sql_error:
                                    st.error(f"âŒ è·å–è¡¨ç»“æ„å¤±è´¥: {sql_error}")
                                    st.markdown("**ğŸ’¡ å¯èƒ½çš„åŸå› :**")
                                    st.markdown("â€¢ è¡¨å°šæœªåˆ›å»ºï¼ˆè¯·å…ˆä½¿ç”¨ç›¸åº”åŠŸèƒ½ç”Ÿæˆæ•°æ®ï¼‰")
                                    st.markdown("â€¢ æ•°æ®åº“è¿æ¥é—®é¢˜")
                                    st.markdown("â€¢ æƒé™ä¸è¶³")
                    except Exception as e:
                        st.error(f"æ“ä½œå¤±è´¥: {e}")
    else:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ ç‚¹å‡» 'ğŸš€ åˆå§‹åŒ–ç³»ç»Ÿ' æŒ‰é’®æ¥æŸ¥çœ‹å…·ä½“é…ç½®ä¿¡æ¯")

        # æ˜¾ç¤ºé€šç”¨çš„å­˜å‚¨æœåŠ¡ä»‹ç»
        st.markdown("### ğŸ“š å­˜å‚¨æœåŠ¡ç±»å‹ä»‹ç»")

        st.markdown("""
        <div class="feature-card">
            <h4>ğŸ¯ 6ç§å­˜å‚¨æœåŠ¡çš„å½¢è±¡ç±»æ¯”</h4>
            <p>ä¸ºäº†å¸®åŠ©ç†è§£ä¸åŒå­˜å‚¨æœåŠ¡çš„ä½œç”¨ï¼Œæˆ‘ä»¬ç”¨ç”Ÿæ´»ä¸­ç†Ÿæ‚‰çš„åœºæ™¯æ¥ç±»æ¯”ï¼š</p>
        </div>
        """, unsafe_allow_html=True)

        # æ·»åŠ ç±»æ¯”è¯´æ˜
        st.markdown("#### ğŸ  ç”Ÿæ´»åœºæ™¯ç±»æ¯”")

        analogy_col1, analogy_col2, analogy_col3 = st.columns(3)

        with analogy_col1:
            st.markdown("""
            **ğŸ“„ DocumentStore = ğŸ“š å›¾ä¹¦é¦†**
            - åƒå›¾ä¹¦é¦†çš„ä¹¦æ¶ï¼Œæ¯æœ¬ä¹¦éƒ½æœ‰ï¼š
            - ğŸ“– ä¹¦åï¼ˆæ ‡é¢˜ï¼‰
            - ğŸ“ å†…å®¹ï¼ˆæ­£æ–‡ï¼‰
            - ğŸ·ï¸ æ ‡ç­¾ï¼ˆå…ƒæ•°æ®ï¼‰
            - ğŸ“… å…¥åº“æ—¶é—´
            """)

            st.markdown("""
            **ğŸ” VectorStore = ğŸ§  å¤§è„‘è®°å¿†**
            - åƒäººè„‘è®°ä½æ¦‚å¿µçš„"æ„Ÿè§‰"
            - ğŸ¤” "æœºå™¨å­¦ä¹ "å’Œ"AI"å¾ˆç›¸ä¼¼
            - ğŸ”— é€šè¿‡"è¯­ä¹‰ç›¸ä¼¼åº¦"æ‰¾å†…å®¹
            - ğŸ’¡ ç†è§£æ„æ€ï¼Œä¸åªæ˜¯å…³é”®è¯
            """)

        with analogy_col2:
            st.markdown("""
            **ğŸ”‘ Store (Cache) = ğŸ—‚ï¸ ä¾¿ç­¾çº¸**
            - åƒè´´åœ¨å†°ç®±ä¸Šçš„ä¾¿ç­¾
            - ğŸ“ ç®€å•çš„é”®å€¼å¯¹
            - â° å¯ä»¥è®¾ç½®è¿‡æœŸæ—¶é—´
            - ğŸƒ å­˜å–é€Ÿåº¦å¾ˆå¿«
            """)

            st.markdown("""
            **ğŸ“ FileStore = ğŸ“¦ ä»“åº“**
            - åƒä»“å‚¨ä¸­å¿ƒçš„å¤§ç®±å­
            - ğŸ“¦ å­˜æ”¾å„ç§æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€PDFï¼‰
            - ğŸ·ï¸ æ¯ä¸ªç®±å­æœ‰æ ‡ç­¾
            - ğŸ’¾ é€‚åˆå¤§æ–‡ä»¶å­˜å‚¨
            """)

        with analogy_col3:
            st.markdown("""
            **âš¡ HybridStore = ğŸ” æ™ºèƒ½æœç´¢**
            - åƒç™¾åº¦/è°·æ­Œçš„æœç´¢å¼•æ“
            - ğŸ¯ æ—¢èƒ½ç†è§£æ„æ€ï¼ˆè¯­ä¹‰ï¼‰
            - ğŸ”¤ åˆèƒ½åŒ¹é…å…³é”®è¯
            - âš–ï¸ ä¸¤ç§æ–¹å¼ç»“åˆï¼Œç»“æœæ›´å‡†
            """)

            st.markdown("""
            **ğŸ’¬ ChatHistory = ğŸ“ é€šè¯è®°å½•**
            - åƒæ‰‹æœºçš„èŠå¤©è®°å½•
            - ğŸ‘¤ è®°ä½è°è¯´äº†ä»€ä¹ˆ
            - â° æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
            - ğŸ”„ æ”¯æŒå¤šè½®å¯¹è¯
            """)

        st.divider()

        generic_services = {
            "DocumentStore": {
                "emoji": "ğŸ“„",
                "description": "ç»“æ„åŒ–æ–‡æ¡£å­˜å‚¨ - åƒå›¾ä¹¦é¦†ç®¡ç†ç³»ç»Ÿ",
                "real_world_analogy": "ğŸ“š å›¾ä¹¦é¦†ä¹¦æ¶ï¼šæ¯æœ¬ä¹¦éƒ½æœ‰æ ‡é¢˜ã€å†…å®¹ã€åˆ†ç±»ã€å…¥åº“æ—¥æœŸ",
                "when_to_use": "å½“ä½ éœ€è¦å­˜å‚¨å’Œç®¡ç†å¤§é‡æ–‡æ¡£æ—¶ï¼ˆå¦‚ä¼ä¸šçŸ¥è¯†åº“ã€æ–‡ç« ç®¡ç†ï¼‰",
                "use_cases": ["çŸ¥è¯†åº“ç®¡ç†", "æ–‡æ¡£å½’æ¡£", "å†…å®¹ç®¡ç†", "ä¼ä¸šæ–‡æ¡£ä¸­å¿ƒ"],
                "typical_schema": ["id", "title", "content", "metadata", "created_at", "updated_at"],
                "example": "å­˜å‚¨å…¬å¸çš„æŠ€æœ¯æ–‡æ¡£ã€æ”¿ç­–æ–‡ä»¶ã€äº§å“è¯´æ˜ä¹¦ç­‰"
            },
            "VectorStore": {
                "emoji": "ğŸ”",
                "description": "å‘é‡åŒ–å­˜å‚¨ - åƒå¤§è„‘çš„æ¦‚å¿µè®°å¿†",
                "real_world_analogy": "ğŸ§  å¤§è„‘è®°å¿†ï¼šç†è§£æ¦‚å¿µçš„'æ„Ÿè§‰'ï¼Œæ‰¾åˆ°æ„æ€ç›¸è¿‘çš„å†…å®¹",
                "when_to_use": "å½“ä½ éœ€è¦æ ¹æ®æ„æ€è€Œä¸æ˜¯ç²¾ç¡®è¯æ±‡æ¥æœç´¢æ—¶ï¼ˆå¦‚æ™ºèƒ½é—®ç­”ã€æ¨èç³»ç»Ÿï¼‰",
                "use_cases": ["è¯­ä¹‰æœç´¢", "æ¨èç³»ç»Ÿ", "æ™ºèƒ½é—®ç­”", "å†…å®¹å‘ç°"],
                "typical_schema": ["id", "document_id", "embedding", "metadata", "created_at"],
                "example": "æœç´¢'æœºå™¨å­¦ä¹ 'æ—¶ï¼Œä¹Ÿèƒ½æ‰¾åˆ°å«æœ‰'äººå·¥æ™ºèƒ½'ã€'æ·±åº¦å­¦ä¹ 'çš„æ–‡æ¡£"
            },
            "HybridStore": {
                "emoji": "âš¡",
                "description": "æ··åˆæœç´¢å¼•æ“ - åƒæ™ºèƒ½æœç´¢å¼•æ“",
                "real_world_analogy": "ğŸ” ç™¾åº¦/è°·æ­Œï¼šæ—¢èƒ½ç†è§£æ„æ€ï¼Œåˆèƒ½ç²¾ç¡®åŒ¹é…å…³é”®è¯",
                "when_to_use": "å½“ä½ éœ€è¦æœ€å‡†ç¡®çš„æœç´¢ç»“æœæ—¶ï¼ˆç»“åˆäº†ç²¾ç¡®åŒ¹é…å’Œè¯­ä¹‰ç†è§£ï¼‰",
                "use_cases": ["ä¼ä¸šæœç´¢", "ç”µå•†æœç´¢", "å­¦æœ¯æ£€ç´¢", "å¤šåª’ä½“æœç´¢"],
                "typical_schema": ["id", "content", "embedding", "keywords", "metadata"],
                "example": "æœç´¢'è‹¹æœæ‰‹æœº'æ—¢èƒ½æ‰¾åˆ°ç²¾ç¡®åŒ…å«è¿™äº›è¯çš„æ–‡æ¡£ï¼Œä¹Ÿèƒ½æ‰¾åˆ°ç›¸å…³çš„'iPhone'æ–‡æ¡£"
            },
            "FileStore": {
                "emoji": "ğŸ“",
                "description": "æ–‡ä»¶å­˜å‚¨ç³»ç»Ÿ - åƒäº‘ç›˜ä»“åº“",
                "real_world_analogy": "ğŸ“¦ äº‘ç›˜/ä»“åº“ï¼šå­˜æ”¾å„ç§æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€PDFï¼‰ï¼Œæ¯ä¸ªéƒ½æœ‰æ ‡ç­¾",
                "when_to_use": "å½“ä½ éœ€è¦å­˜å‚¨äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€æ–‡æ¡£ç­‰ï¼‰æ—¶",
                "use_cases": ["å¤šåª’ä½“èµ„æº", "æ•°æ®æ¹–", "å¤‡ä»½å½’æ¡£", "å†…å®¹åˆ†å‘"],
                "typical_schema": ["Volume based", "Binary storage", "File metadata"],
                "example": "å­˜å‚¨äº§å“å›¾ç‰‡ã€ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£ã€è§†é¢‘æ–‡ä»¶ç­‰"
            },
            "Store": {
                "emoji": "ğŸ”‘",
                "description": "é”®å€¼å­˜å‚¨å’Œç¼“å­˜ - åƒä¾¿ç­¾çº¸",
                "real_world_analogy": "ğŸ—‚ï¸ ä¾¿ç­¾çº¸ï¼šç®€å•çš„é”®å€¼å¯¹ï¼Œè´´åœ¨å†°ç®±ä¸Šçš„å¤‡å¿˜å½•",
                "when_to_use": "å½“ä½ éœ€è¦å¿«é€Ÿå­˜å–ç®€å•æ•°æ®æ—¶ï¼ˆå¦‚ç”¨æˆ·ä¼šè¯ã€é…ç½®å‚æ•°ï¼‰",
                "use_cases": ["ä¼šè¯ç®¡ç†", "é…ç½®å­˜å‚¨", "ä¸´æ—¶ç¼“å­˜", "åˆ†å¸ƒå¼é”"],
                "typical_schema": ["key", "value", "expires_at", "created_at"],
                "example": "è®°ä½ç”¨æˆ·ç™»å½•çŠ¶æ€ã€ä¿å­˜åº”ç”¨é…ç½®ã€ä¸´æ—¶ç¼“å­˜è®¡ç®—ç»“æœ"
            },
            "ChatMessageHistory": {
                "emoji": "ğŸ’¬",
                "description": "å¯¹è¯å†å²ç®¡ç† - åƒèŠå¤©è®°å½•",
                "real_world_analogy": "ğŸ“ å¾®ä¿¡èŠå¤©è®°å½•ï¼šæŒ‰æ—¶é—´è®°å½•è°è¯´äº†ä»€ä¹ˆï¼Œæ”¯æŒç¿»çœ‹å†å²",
                "when_to_use": "å½“ä½ éœ€è¦æ„å»ºå¯¹è¯ç³»ç»Ÿæ—¶ï¼ˆå¦‚æ™ºèƒ½å®¢æœã€èŠå¤©æœºå™¨äººï¼‰",
                "use_cases": ["æ™ºèƒ½å®¢æœ", "èŠå¤©æœºå™¨äºº", "AIåŠ©æ‰‹", "å¤šè½®é—®ç­”"],
                "typical_schema": ["session_id", "message_type", "content", "timestamp"],
                "example": "å®¢æœç³»ç»Ÿè®°å½•ç”¨æˆ·å¯¹è¯ï¼ŒAIåŠ©æ‰‹è®°ä½å‰é¢çš„èŠå¤©å†…å®¹"
            }
        }

        for name, info in generic_services.items():
            with st.expander(f"{info['emoji']} {name} - {info['description']}", expanded=False):
                # æ·»åŠ ç”Ÿæ´»åŒ–ç±»æ¯”
                st.markdown(f"**ğŸ  ç”Ÿæ´»ç±»æ¯”:** {info['real_world_analogy']}")
                st.markdown(f"**ğŸ¯ ä½¿ç”¨åœºæ™¯:** {info['when_to_use']}")
                st.markdown(f"**ğŸ’¡ å®é™…ä¾‹å­:** {info['example']}")

                st.divider()

                col1, col2 = st.columns([1, 1])

                with col1:
                    st.markdown("**ğŸ’¼ åº”ç”¨åœºæ™¯:**")
                    for use_case in info['use_cases']:
                        st.markdown(f"â€¢ {use_case}")

                with col2:
                    st.markdown("**ğŸ—ƒï¸ å…¸å‹è¡¨ç»“æ„:**")
                    for field in info['typical_schema']:
                        st.markdown(f"â€¢ `{field}`")


def show_code_examples():
    """æ˜¾ç¤ºä»£ç ç¤ºä¾‹"""
    st.subheader("ğŸ“ ä»£ç ç¤ºä¾‹å’Œå®ç°æ¨¡æ¿")

    # åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
    st.markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹")

    basic_example = '''
# 1. åˆå§‹åŒ– ClickZetta å¼•æ“
from langchain_clickzetta import ClickZettaEngine

engine = ClickZettaEngine(
    service=os.getenv("CLICKZETTA_SERVICE"),
    instance=os.getenv("CLICKZETTA_INSTANCE"),
    workspace=os.getenv("CLICKZETTA_WORKSPACE"),
    schema=os.getenv("CLICKZETTA_SCHEMA"),
    username=os.getenv("CLICKZETTA_USERNAME"),
    password=os.getenv("CLICKZETTA_PASSWORD"),
    vcluster=os.getenv("CLICKZETTA_VCLUSTER")
)

# 2. åˆ›å»ºå­˜å‚¨æœåŠ¡
from langchain_clickzetta import ClickZettaDocumentStore

document_store = ClickZettaDocumentStore(
    engine=engine,
    table_name="my_documents"
)

# 3. å­˜å‚¨æ–‡æ¡£
from langchain_core.documents import Document

document = Document(
    page_content="è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡æ¡£å†…å®¹",
    metadata={"title": "ç¤ºä¾‹æ–‡æ¡£", "category": "æ¼”ç¤º"}
)

document_store.add_document(document)

# 4. æœç´¢æ–‡æ¡£
results = document_store.search("ç¤ºä¾‹", k=5)
for doc in results:
    print(f"æ ‡é¢˜: {doc.metadata['title']}")
    print(f"å†…å®¹: {doc.page_content[:100]}...")
'''

    st.code(basic_example, language="python")

    # é«˜çº§åŠŸèƒ½ç¤ºä¾‹
    st.markdown("### âš¡ é«˜çº§åŠŸèƒ½ç¤ºä¾‹")

    advanced_tabs = st.tabs(["å‘é‡æœç´¢", "æ··åˆæœç´¢", "å¯¹è¯å†å²", "æ–‡ä»¶å­˜å‚¨", "é”®å€¼ç¼“å­˜"])

    with advanced_tabs[0]:
        st.markdown("**å‘é‡æœç´¢å’Œè¯­ä¹‰æ£€ç´¢:**")
        vector_example = '''
from langchain_clickzetta import ClickZettaVectorStore
from langchain_community.embeddings import DashScopeEmbeddings

# åˆå§‹åŒ–å‘é‡å­˜å‚¨
embeddings = DashScopeEmbeddings(model="text-embedding-v1")
vector_store = ClickZettaVectorStore(
    engine=engine,
    embedding=embeddings,
    table_name="my_vectors"
)

# æ·»åŠ æ–‡æ¡£ï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰
vector_store.add_document(document)

# è¯­ä¹‰æœç´¢
results = vector_store.similarity_search(
    "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ",
    k=3,
    score_threshold=0.7
)

# å¸¦åˆ†æ•°çš„æœç´¢
results_with_scores = vector_store.similarity_search_with_score(
    "æ·±åº¦å­¦ä¹ æŠ€æœ¯",
    k=5
)

for doc, score in results_with_scores:
    print(f"ç›¸ä¼¼åº¦: {score:.3f}")
    print(f"å†…å®¹: {doc.page_content[:100]}...")
'''
        st.code(vector_example, language="python")

    with advanced_tabs[1]:
        st.markdown("**æ··åˆæœç´¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰:**")
        hybrid_example = '''
from langchain_clickzetta import ClickZettaHybridStore

# åˆå§‹åŒ–æ··åˆå­˜å‚¨
hybrid_store = ClickZettaHybridStore(
    engine=engine,
    embedding=embeddings,
    table_name="my_hybrid"
)

# æ·»åŠ æ–‡æ¡£
hybrid_store.add_document(document)

# æ··åˆæœç´¢ï¼ˆå¯è°ƒæƒé‡ï¼‰
results = hybrid_store.search(
    query="æœºå™¨å­¦ä¹ ç®—æ³•",
    search_type="hybrid",  # "semantic", "keyword", "hybrid"
    k=5,
    alpha=0.5  # 0.0=çº¯å…³é”®è¯, 1.0=çº¯å‘é‡, 0.5=å¹³è¡¡
)

# è¯­ä¹‰æœç´¢
semantic_results = hybrid_store.search(
    query="äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
    search_type="semantic",
    k=3
)

# å…³é”®è¯æœç´¢
keyword_results = hybrid_store.search(
    query="Python ç¼–ç¨‹ æ•™ç¨‹",
    search_type="keyword",
    k=3
)
'''
        st.code(hybrid_example, language="python")

    with advanced_tabs[2]:
        st.markdown("**å¯¹è¯å†å²ç®¡ç†:**")
        chat_example = '''
from langchain_clickzetta import ClickZettaChatMessageHistory
from langchain_core.messages import HumanMessage, AIMessage

# åˆå§‹åŒ–å¯¹è¯å†å²
chat_history = ClickZettaChatMessageHistory(
    engine=engine,
    session_id="user_123",
    table_name="chat_sessions"
)

# æ·»åŠ æ¶ˆæ¯
chat_history.add_message(HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ "))
chat_history.add_message(AIMessage(content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..."))

# è·å–å†å²æ¶ˆæ¯
messages = chat_history.get_messages()
for msg in messages:
    role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "AI"
    print(f"{role}: {msg.content}")

# æ¸…é™¤å†å²
chat_history.clear()

# è·å–æœ€è¿‘çš„ N æ¡æ¶ˆæ¯
recent_messages = chat_history.get_recent_messages(n=10)
'''
        st.code(chat_example, language="python")

    with advanced_tabs[3]:
        st.markdown("**æ–‡ä»¶å­˜å‚¨å’Œç®¡ç†:**")
        file_example = '''
from langchain_clickzetta import ClickZettaFileStore

# åˆå§‹åŒ–æ–‡ä»¶å­˜å‚¨
file_store = ClickZettaFileStore(
    engine=engine,
    volume_name="my_files"
)

# å­˜å‚¨æ–‡ä»¶
with open("document.pdf", "rb") as f:
    file_content = f.read()

file_store.store(
    key="docs/important_document.pdf",
    content=file_content,
    metadata={
        "content_type": "application/pdf",
        "size": len(file_content),
        "uploaded_by": "user_123"
    }
)

# è¯»å–æ–‡ä»¶
retrieved_content = file_store.retrieve("docs/important_document.pdf")

# åˆ—å‡ºæ–‡ä»¶
files = file_store.list_files(prefix="docs/")
for file_info in files:
    print(f"æ–‡ä»¶: {file_info['key']}")
    print(f"å¤§å°: {file_info['size']} bytes")

# åˆ é™¤æ–‡ä»¶
file_store.delete("docs/old_document.pdf")
'''
        st.code(file_example, language="python")

    with advanced_tabs[4]:
        st.markdown("**é”®å€¼å­˜å‚¨å’Œç¼“å­˜:**")
        cache_example = '''
from langchain_clickzetta import ClickZettaStore
import json
from datetime import datetime, timedelta

# åˆå§‹åŒ–é”®å€¼å­˜å‚¨
cache_store = ClickZettaStore(
    engine=engine,
    table_name="my_cache"
)

# å­˜å‚¨ç®€å•å€¼
cache_store.set("user_session", "active")
cache_store.set("login_count", 42)

# å­˜å‚¨å¤æ‚å¯¹è±¡
user_profile = {
    "user_id": "123",
    "name": "å¼ ä¸‰",
    "preferences": ["AI", "æœºå™¨å­¦ä¹ "],
    "last_login": datetime.now().isoformat()
}
cache_store.set("user_profile_123", json.dumps(user_profile))

# å¸¦è¿‡æœŸæ—¶é—´çš„å­˜å‚¨
expiry_time = datetime.now() + timedelta(hours=1)
cache_store.set("temp_token", "abc123", expires_at=expiry_time)

# è¯»å–å€¼
session_status = cache_store.get("user_session")
user_data = json.loads(cache_store.get("user_profile_123"))

# æ‰¹é‡æ“ä½œ
cache_store.batch_set({
    "config_theme": "dark",
    "config_language": "zh-CN",
    "config_notifications": True
})

batch_data = cache_store.batch_get(["config_theme", "config_language"])

# åˆ é™¤
cache_store.delete("temp_token")

# æ£€æŸ¥å­˜åœ¨æ€§
if cache_store.exists("user_session"):
    print("ç”¨æˆ·ä¼šè¯å­˜åœ¨")
'''
        st.code(cache_example, language="python")


def show_best_practices():
    """æ˜¾ç¤ºæœ€ä½³å®è·µæŒ‡å—"""
    st.subheader("ğŸš€ æœ€ä½³å®è·µå’Œå¼€å‘å»ºè®®")

    # æ€§èƒ½ä¼˜åŒ–
    st.markdown("### âš¡ æ€§èƒ½ä¼˜åŒ–")

    perf_tips = {
        "è¿æ¥ç®¡ç†": [
            "å¤ç”¨ ClickZettaEngine å®ä¾‹ï¼Œé¿å…é¢‘ç¹åˆ›å»ºè¿æ¥",
            "ä½¿ç”¨è¿æ¥æ± ç®¡ç†å¹¶å‘è®¿é—®",
            "åˆç†è®¾ç½®è¿æ¥è¶…æ—¶å‚æ•°",
            "å®šæœŸæ¸…ç†ç©ºé—²è¿æ¥"
        ],
        "å­˜å‚¨ä¼˜åŒ–": [
            "é€‰æ‹©åˆé€‚çš„è¡¨åå’Œç´¢å¼•ç­–ç•¥",
            "æ‰¹é‡æ“ä½œæ—¶ä½¿ç”¨ batch_add ç­‰æ–¹æ³•",
            "å¤§æ–‡ä»¶å­˜å‚¨ä¼˜å…ˆä½¿ç”¨ FileStore",
            "å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®å’Œç¼“å­˜"
        ],
        "å‘é‡æœç´¢": [
            "é€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹å’Œç»´åº¦",
            "è®¾ç½®åˆç†çš„ç›¸ä¼¼åº¦é˜ˆå€¼",
            "ä½¿ç”¨åˆ†é¡µæŸ¥è¯¢å¤„ç†å¤§ç»“æœé›†",
            "ç¼“å­˜å¸¸ç”¨æŸ¥è¯¢çš„å‘é‡è¡¨ç¤º"
        ],
        "å†…å­˜ç®¡ç†": [
            "åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡å’Œæ–‡ä»¶å¥æŸ„",
            "ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ•°æ®é›†",
            "ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ",
            "åˆç†è®¾ç½®æ‰¹å¤„ç†å¤§å°"
        ]
    }

    for category, tips in perf_tips.items():
        with st.expander(f"ğŸ”§ {category}", expanded=False):
            for tip in tips:
                st.markdown(f"â€¢ {tip}")

    # å®‰å…¨æœ€ä½³å®è·µ
    st.markdown("### ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ")

    security_code = '''
# 1. ç¯å¢ƒå˜é‡ç®¡ç†
import os
from dotenv import load_dotenv

# æ°¸è¿œä¸è¦ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
# âŒ é”™è¯¯åšæ³•
# engine = ClickZettaEngine(
#     service="my-service",
#     username="admin",
#     password="password123"  # å±é™©ï¼
# )

# âœ… æ­£ç¡®åšæ³•
load_dotenv()
engine = ClickZettaEngine(
    service=os.getenv("CLICKZETTA_SERVICE"),
    username=os.getenv("CLICKZETTA_USERNAME"),
    password=os.getenv("CLICKZETTA_PASSWORD")
)

# 2. è¾“å…¥éªŒè¯å’Œæ¸…ç†
def sanitize_input(content):
    """æ¸…ç†ç”¨æˆ·è¾“å…¥ï¼Œé˜²æ­¢æ³¨å…¥æ”»å‡»"""
    if not content:
        return content

    # ç§»é™¤å±é™©å­—ç¬¦
    dangerous_chars = ['<', '>', '"', "'", '&', '\\x00']
    for char in dangerous_chars:
        content = content.replace(char, '')

    # é™åˆ¶é•¿åº¦
    max_length = 10000
    if len(content) > max_length:
        content = content[:max_length] + "...[æˆªæ–­]"

    return content

# 3. é”™è¯¯å¤„ç†ï¼ˆä¸æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼‰
try:
    result = engine.execute_sql(query)
except Exception as e:
    # âŒ ä¸è¦ç›´æ¥æš´éœ²è¯¦ç»†é”™è¯¯
    # print(f"Database error: {str(e)}")

    # âœ… è®°å½•è¯¦ç»†é”™è¯¯ï¼Œè¿”å›é€šç”¨æ¶ˆæ¯
    logger.error(f"Database operation failed: {str(e)}")
    return {"error": "æ“ä½œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"}
'''

    st.code(security_code, language="python")

    # å­¦ä¹ èµ„æº
    st.markdown("### ğŸ“š å­¦ä¹ èµ„æºå’Œç¤¾åŒº")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**ğŸ“– å®˜æ–¹æ–‡æ¡£:**")
        st.markdown("â€¢ [ClickZetta å®˜æ–¹æ–‡æ¡£](https://www.yunqi.tech/documents/)")
        st.markdown("â€¢ [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com)")
        st.markdown("â€¢ [é€šä¹‰åƒé—® API æ–‡æ¡£](https://help.aliyun.com/product/2400395.html)")
        st.markdown("â€¢ [Streamlit å¼€å‘æŒ‡å—](https://docs.streamlit.io)")

    with col2:
        st.markdown("**ğŸ› ï¸ å¼€å‘å·¥å…·:**")
        st.markdown("â€¢ Jupyter Notebook äº¤äº’å¼å¼€å‘")
        st.markdown("â€¢ VS Code + Python æ‰©å±•")
        st.markdown("â€¢ Docker Desktop å®¹å™¨åŒ–")
        st.markdown("â€¢ Git ç‰ˆæœ¬æ§åˆ¶")

    st.markdown("**ğŸ’¡ å¼€å‘å»ºè®®:**")
    st.info("""
    1. **ä»ç®€å•å¼€å§‹**: å…ˆæŒæ¡å•ä¸ªå­˜å‚¨æœåŠ¡ï¼Œå†å°è¯•å¤æ‚çš„ç»„åˆä½¿ç”¨
    2. **å¤šå®è·µ**: é€šè¿‡å®é™…é¡¹ç›®åŠ æ·±å¯¹ ClickZetta LangChain çš„ç†è§£
    3. **å…³æ³¨æ€§èƒ½**: åœ¨å¼€å‘è¿‡ç¨‹ä¸­å…³æ³¨æŸ¥è¯¢æ€§èƒ½å’Œèµ„æºä½¿ç”¨
    4. **ç¤¾åŒºå‚ä¸**: ç§¯æå‚ä¸å¼€æºç¤¾åŒºï¼Œåˆ†äº«ç»éªŒå’Œæœ€ä½³å®è·µ
    5. **æŒç»­å­¦ä¹ **: è·Ÿä¸Š AI å’Œæ•°æ®æŠ€æœ¯çš„æœ€æ–°å‘å±•è¶‹åŠ¿
    """)


# ä¸»å†…å®¹åŒºåŸŸ
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    "ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ",
    "ğŸ“ æ–‡æ¡£å­˜å‚¨",
    "ğŸ“„ æ™ºèƒ½æ‘˜è¦",
    "ğŸ’¬ æ™ºèƒ½é—®ç­”",
    "ğŸ” æ··åˆæœç´¢",
    "ğŸ•·ï¸ ç½‘ç»œçˆ¬è™«",
    "ğŸ’¾ SQLé—®ç­”",
    "ğŸ’¡ å¸®åŠ©æ–‡æ¡£"
])

with tab1:
    show_overview()

with tab2:
    show_document_storage()

with tab3:
    show_intelligent_summary()

with tab4:
    show_qa_system()

with tab5:
    show_search_system()

with tab6:
    show_web_crawler()

with tab7:
    show_sql_chat()

with tab8:
    show_help_documentation()

# é¡µè„š
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    <p>ğŸš€ ClickZetta LangChain All-in-One Demo |
    å±•ç¤ºä¼ä¸šçº§ AI åº”ç”¨çš„å®Œæ•´æŠ€æœ¯æ ˆ</p>
</div>
""", unsafe_allow_html=True)